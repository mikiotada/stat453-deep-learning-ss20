{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 453: Deep Learning (Spring 2020)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2020/  \n",
    "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss20\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom DataLoader Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustration of how we can efficiently iterate through custom (image) datasets. For this, suppose \n",
    "- mnist_train, mnist_valid, and mnist_test are image folders you created with your own custom images\n",
    "- mnist_train.csv, mnist_valid.csv, and mnist_test.csv are tables that store the image names with their associated class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.7.1\n",
      "IPython 7.12.0\n",
      "\n",
      "torch 1.4.0\n",
      "pandas 1.0.1\n",
      "numpy 1.18.1\n",
      "matplotlib 3.1.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch,pandas,numpy,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Inspecting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc44105e400>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = Image.open('mnist_train/1.png')\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Dimensions (28, 28)\n",
      "\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1  18  38 136 227 255\n",
      "  254 132   0  90 136  98   3   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  82 156 253 253 253 253 253\n",
      "  253 249 154 219 253 253  35   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  40 150 244 253 253 253 253 253 253\n",
      "  253 253 253 253 253 253  35   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  74 237 253 253 253 253 253 203 182 242\n",
      "  253 253 253 253 253 230  25   0   0   0]\n",
      " [  0   0   0   0   0   0   0  13 200 253 253 253 168 164  91  14  64 246\n",
      "  253 253 253 195  79  32   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  21 219 253 253 159   2   0   0 103 233 253\n",
      "  253 253 177  10   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 171 253 253 147   0   1 155 250 253 253\n",
      "  251 126   5   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 101 236 253 206  32 152 253 253 253 253\n",
      "  130   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  91 253 253 253 253 253 253 241 113\n",
      "    9   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  91 243 253 253 253 253 239  81   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 207 253 253 253 253 158   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 207 253 253 253 253 121   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  24 145 249 253 253 253 253 194   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  59 253 253 253 253 253 253 224  30   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   5 181 253 253 241 114 240 253 253 136   5\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  36 253 253 253 125   0  65 253 253 253  41\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  67 253 253 253  29   2 138 253 253 253  41\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  60 253 253 253 207 202 253 253 253 192   9\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   5 183 253 253 253 253 253 253 230  52   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  62 253 253 253 253 242 116  13   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "im_array = np.array(im)\n",
    "print('Array Dimensions', im_array.shape)\n",
    "print()\n",
    "print(im_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "      <th>File Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Label File Name\n",
       "0            5     0.png\n",
       "1            8     1.png\n",
       "2            8     2.png\n",
       "3            0     3.png\n",
       "4            9     4.png"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('mnist_train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "      <th>File Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>256.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>257.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>258.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>259.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>260.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Label File Name\n",
       "0            0   256.png\n",
       "1            8   257.png\n",
       "2            7   258.png\n",
       "3            4   259.png\n",
       "4            7   260.png"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv('mnist_valid.csv')\n",
    "print(df_valid.shape)\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "      <th>File Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>512.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>513.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>514.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>515.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>516.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Label File Name\n",
       "0            4   512.png\n",
       "1            0   513.png\n",
       "2            6   514.png\n",
       "3            8   515.png\n",
       "4            4   516.png"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('mnist_test.csv')\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "    \n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = df['File Name']\n",
    "        self.y = df['Class Label']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Custom Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Note that transforms.ToTensor()\n",
    "# already divides pixels by 255. internally\n",
    "\n",
    "custom_transform = transforms.Compose([#transforms.Lambda(lambda x: x/255.), # not necessary\n",
    "                                       transforms.ToTensor()\n",
    "                                      ])\n",
    "\n",
    "train_dataset = MyDataset(csv_path='mnist_train.csv',\n",
    "                          img_dir='mnist_train',\n",
    "                          transform=custom_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True, # want to shuffle the dataset\n",
    "                          num_workers=4) # number processes/CPUs to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = MyDataset(csv_path='mnist_valid.csv',\n",
    "                          img_dir='mnist_valid',\n",
    "                          transform=custom_transform)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=100,\n",
    "                          shuffle=False,\n",
    "                          num_workers=4)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = MyDataset(csv_path='mnist_test.csv',\n",
    "                         img_dir='mnist_test',\n",
    "                         transform=custom_transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=100,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Iterating Through the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 1 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 2 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 3 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 4 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 5 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 6 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 7 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 1 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 2 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 3 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 4 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 5 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 6 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 7 | Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784])\n"
     ]
    }
   ],
   "source": [
    "x_image_as_vector = x.view(-1, 28*28)\n",
    "print(x_image_as_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
