{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 453: Deep Learning (Spring 2020)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2020/  \n",
    "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.7.5\n",
      "IPython 7.10.2\n",
      "\n",
      "torch 1.4.0\n",
      "pandas 0.25.3\n",
      "matplotlib 3.1.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch,pandas,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/adaline-concept.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that linear regression and Adaline are very similar. The only difference is that we apply a threshold function for converting the outputs from continuous targets for predictions. The derivative and training procedure are identical to Adaline though. You can compare the two notebooks (this one and `adaline-sgd.ipynb`) side by side as shown below to see the relationship:\n",
    "\n",
    "![](figures/adaline-vs-linreg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Prepare a Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.942094</td>\n",
       "      <td>-0.835856</td>\n",
       "      <td>-22.324428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.222445</td>\n",
       "      <td>-0.403177</td>\n",
       "      <td>-52.121493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.112466</td>\n",
       "      <td>-1.688230</td>\n",
       "      <td>-57.043196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.403459</td>\n",
       "      <td>-0.412272</td>\n",
       "      <td>-27.701833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.021351</td>\n",
       "      <td>-0.499017</td>\n",
       "      <td>-9.804714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2          y\n",
       "995 -0.942094 -0.835856 -22.324428\n",
       "996  1.222445 -0.403177 -52.121493\n",
       "997 -0.112466 -1.688230 -57.043196\n",
       "998 -0.403459 -0.412272 -27.701833\n",
       "999  0.021351 -0.499017  -9.804714"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/linreg-data.csv', index_col=0)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign features and target\n",
    "\n",
    "X = torch.tensor(df[['x1', 'x2']].values, dtype=torch.float)\n",
    "y = torch.tensor(df['y'].values, dtype=torch.float)\n",
    "\n",
    "# Shuffling & train/test split\n",
    "\n",
    "torch.manual_seed(123)\n",
    "shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
    "\n",
    "X, y = X[shuffle_idx], y[shuffle_idx]\n",
    "\n",
    "percent70 = int(shuffle_idx.size(0)*0.7)\n",
    "\n",
    "X_train, X_test = X[shuffle_idx[:percent70]], X[shuffle_idx[percent70:]]\n",
    "y_train, y_test = y[shuffle_idx[:percent70]], y[shuffle_idx[percent70:]]\n",
    "\n",
    "# Normalize (mean zero, unit variance)\n",
    "\n",
    "mu, sigma = X_train.mean(dim=0), X_train.std(dim=0)\n",
    "X_train = (X_train - mu) / sigma\n",
    "X_test = (X_test - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression1():\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.weights = torch.zeros(num_features, 1, \n",
    "                                   dtype=torch.float)\n",
    "        self.bias = torch.zeros(1, dtype=torch.float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        netinputs = torch.add(torch.mm(x, self.weights), self.bias)\n",
    "        activations = netinputs\n",
    "        return activations.view(-1)\n",
    "        \n",
    "    def backward(self, x, yhat, y):  \n",
    "        \n",
    "        grad_loss_yhat = 2*(y - yhat)\n",
    "        \n",
    "        grad_yhat_weights = -x\n",
    "        grad_yhat_bias = -1.\n",
    "        \n",
    "        # Chain rule: inner times outer\n",
    "        grad_loss_weights =  torch.mm(grad_yhat_weights.t(),\n",
    "                                         grad_loss_yhat.view(-1, 1)) / y.size(0)\n",
    "\n",
    "        grad_loss_bias = torch.sum(grad_yhat_bias*grad_loss_yhat) / y.size(0)\n",
    "        \n",
    "        # return negative gradient\n",
    "        return (-1)*grad_loss_weights, (-1)*grad_loss_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "##### Training and evaluation wrappers\n",
    "###################################################\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return torch.mean((yhat - y)**2)\n",
    "\n",
    "\n",
    "def train(model, x, y, num_epochs, learning_rate=0.01):\n",
    "    cost = []\n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        #### Compute outputs ####\n",
    "        yhat = model.forward(x)\n",
    "\n",
    "        #### Compute gradients ####\n",
    "        negative_grad_w, negative_grad_b = model.backward(x, yhat, y)\n",
    "\n",
    "        #### Update weights ####\n",
    "        model.weights += learning_rate * negative_grad_w\n",
    "        model.bias += learning_rate * negative_grad_b\n",
    "\n",
    "        #### Logging ####\n",
    "        yhat = model.forward(x) # not that this is a bit wasteful here\n",
    "        curr_loss = loss(yhat, y)\n",
    "        print('Epoch: %03d' % (e+1), end=\"\")\n",
    "        print(' | MSE: %.5f' % curr_loss)\n",
    "        cost.append(curr_loss)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | MSE: 1532.67590\n",
      "Epoch: 002 | MSE: 1312.39832\n",
      "Epoch: 003 | MSE: 1133.91785\n",
      "Epoch: 004 | MSE: 989.30280\n",
      "Epoch: 005 | MSE: 872.12573\n",
      "Epoch: 006 | MSE: 777.18127\n",
      "Epoch: 007 | MSE: 700.24915\n",
      "Epoch: 008 | MSE: 637.91260\n",
      "Epoch: 009 | MSE: 587.40167\n",
      "Epoch: 010 | MSE: 546.47278\n",
      "Epoch: 011 | MSE: 513.30798\n",
      "Epoch: 012 | MSE: 486.43439\n",
      "Epoch: 013 | MSE: 464.65799\n",
      "Epoch: 014 | MSE: 447.01218\n",
      "Epoch: 015 | MSE: 432.71335\n",
      "Epoch: 016 | MSE: 421.12643\n",
      "Epoch: 017 | MSE: 411.73709\n",
      "Epoch: 018 | MSE: 404.12839\n",
      "Epoch: 019 | MSE: 397.96268\n",
      "Epoch: 020 | MSE: 392.96613\n",
      "Epoch: 021 | MSE: 388.91714\n",
      "Epoch: 022 | MSE: 385.63589\n",
      "Epoch: 023 | MSE: 382.97693\n",
      "Epoch: 024 | MSE: 380.82196\n",
      "Epoch: 025 | MSE: 379.07571\n",
      "Epoch: 026 | MSE: 377.66058\n",
      "Epoch: 027 | MSE: 376.51376\n",
      "Epoch: 028 | MSE: 375.58420\n",
      "Epoch: 029 | MSE: 374.83099\n",
      "Epoch: 030 | MSE: 374.22055\n",
      "Epoch: 031 | MSE: 373.72589\n",
      "Epoch: 032 | MSE: 373.32486\n",
      "Epoch: 033 | MSE: 372.99991\n",
      "Epoch: 034 | MSE: 372.73657\n",
      "Epoch: 035 | MSE: 372.52307\n",
      "Epoch: 036 | MSE: 372.35016\n",
      "Epoch: 037 | MSE: 372.20999\n",
      "Epoch: 038 | MSE: 372.09637\n",
      "Epoch: 039 | MSE: 372.00424\n",
      "Epoch: 040 | MSE: 371.92966\n",
      "Epoch: 041 | MSE: 371.86914\n",
      "Epoch: 042 | MSE: 371.82004\n",
      "Epoch: 043 | MSE: 371.78036\n",
      "Epoch: 044 | MSE: 371.74820\n",
      "Epoch: 045 | MSE: 371.72198\n",
      "Epoch: 046 | MSE: 371.70093\n",
      "Epoch: 047 | MSE: 371.68372\n",
      "Epoch: 048 | MSE: 371.66977\n",
      "Epoch: 049 | MSE: 371.65860\n",
      "Epoch: 050 | MSE: 371.64938\n",
      "Epoch: 051 | MSE: 371.64209\n",
      "Epoch: 052 | MSE: 371.63602\n",
      "Epoch: 053 | MSE: 371.63120\n",
      "Epoch: 054 | MSE: 371.62720\n",
      "Epoch: 055 | MSE: 371.62402\n",
      "Epoch: 056 | MSE: 371.62146\n",
      "Epoch: 057 | MSE: 371.61929\n",
      "Epoch: 058 | MSE: 371.61765\n",
      "Epoch: 059 | MSE: 371.61618\n",
      "Epoch: 060 | MSE: 371.61508\n",
      "Epoch: 061 | MSE: 371.61423\n",
      "Epoch: 062 | MSE: 371.61349\n",
      "Epoch: 063 | MSE: 371.61288\n",
      "Epoch: 064 | MSE: 371.61240\n",
      "Epoch: 065 | MSE: 371.61200\n",
      "Epoch: 066 | MSE: 371.61172\n",
      "Epoch: 067 | MSE: 371.61139\n",
      "Epoch: 068 | MSE: 371.61118\n",
      "Epoch: 069 | MSE: 371.61108\n",
      "Epoch: 070 | MSE: 371.61096\n",
      "Epoch: 071 | MSE: 371.61075\n",
      "Epoch: 072 | MSE: 371.61069\n",
      "Epoch: 073 | MSE: 371.61063\n",
      "Epoch: 074 | MSE: 371.61050\n",
      "Epoch: 075 | MSE: 371.61057\n",
      "Epoch: 076 | MSE: 371.61053\n",
      "Epoch: 077 | MSE: 371.61050\n",
      "Epoch: 078 | MSE: 371.61041\n",
      "Epoch: 079 | MSE: 371.61041\n",
      "Epoch: 080 | MSE: 371.61044\n",
      "Epoch: 081 | MSE: 371.61041\n",
      "Epoch: 082 | MSE: 371.61035\n",
      "Epoch: 083 | MSE: 371.61041\n",
      "Epoch: 084 | MSE: 371.61032\n",
      "Epoch: 085 | MSE: 371.61032\n",
      "Epoch: 086 | MSE: 371.61035\n",
      "Epoch: 087 | MSE: 371.61038\n",
      "Epoch: 088 | MSE: 371.61032\n",
      "Epoch: 089 | MSE: 371.61035\n",
      "Epoch: 090 | MSE: 371.61026\n",
      "Epoch: 091 | MSE: 371.61029\n",
      "Epoch: 092 | MSE: 371.61032\n",
      "Epoch: 093 | MSE: 371.61032\n",
      "Epoch: 094 | MSE: 371.61038\n",
      "Epoch: 095 | MSE: 371.61035\n",
      "Epoch: 096 | MSE: 371.61035\n",
      "Epoch: 097 | MSE: 371.61026\n",
      "Epoch: 098 | MSE: 371.61035\n",
      "Epoch: 099 | MSE: 371.61035\n",
      "Epoch: 100 | MSE: 371.61032\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression1(num_features=X_train.size(1))\n",
    "cost = train(model, \n",
    "             X_train, y_train, \n",
    "             num_epochs=100, \n",
    "             learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(cost)), cost)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 371.61032\n",
      "Test MSE: 406.88403\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.forward(X_train)\n",
    "test_pred = model.forward(X_test)\n",
    "\n",
    "print('Train MSE: %.5f' % loss(train_pred, y_train))\n",
    "print('Test MSE: %.5f' % loss(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with analytical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights tensor([[ 0.3623],\n",
      "        [37.8790]])\n",
      "Bias tensor([-0.5464])\n"
     ]
    }
   ],
   "source": [
    "print('Weights', model.weights)\n",
    "print('Bias', model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical weights tensor([[ 0.3624],\n",
      "        [37.8801]])\n",
      "Analytical bias tensor([-0.5464])\n"
     ]
    }
   ],
   "source": [
    "def analytical_solution(x, y):\n",
    "    Xb = torch.cat( (torch.ones((x.size(0), 1)), x), dim=1)\n",
    "    w = torch.zeros(x.size(1))\n",
    "    z = torch.inverse(torch.matmul(Xb.t(), Xb))\n",
    "    params = torch.matmul(z, torch.matmul(Xb.t(), y))\n",
    "    b, w = torch.tensor([params[0]]), params[1:].view(x.size(1), 1)\n",
    "    return w, b\n",
    "\n",
    "w, b = analytical_solution(X_train, y_train)\n",
    "print('Analytical weights', w)\n",
    "print('Analytical bias', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Ungraded) HW Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the `train()` function such that the dataset is shuffled prior to each epoch. Do you see a difference -- Yes/No? Try to come up with an explanation for your observation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
