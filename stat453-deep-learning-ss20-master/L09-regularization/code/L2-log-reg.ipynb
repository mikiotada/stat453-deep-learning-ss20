{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 453: Deep Learning (Spring 2020)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2020/  \n",
    "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.7.1\n",
      "IPython 7.12.0\n",
      "\n",
      "torch 1.4.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Runs on CPU or GPU (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of *classic* logistic regression for binary class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "LAMBDA = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x180 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################\n",
    "### DATASET\n",
    "##########################\n",
    "\n",
    "data = np.genfromtxt('data/toydata.txt', delimiter='\\t')\n",
    "x = data[:, :2].astype(np.float32)\n",
    "y = data[:, 2].astype(np.int64)\n",
    "\n",
    "np.random.seed(123)\n",
    "idx = np.arange(y.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "X_test, y_test = x[idx[:25]], y[idx[:25]]\n",
    "X_train, y_train = x[idx[25:]], y[idx[25:]]\n",
    "mu, std = np.mean(X_train, axis=0), np.std(X_train, axis=0)\n",
    "X_train, X_test = (X_train - mu) / std, (X_test - mu) / std\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 2.5))\n",
    "ax[0].scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1])\n",
    "ax[0].scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1])\n",
    "ax[1].scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1])\n",
    "ax[1].scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1])\n",
    "plt.xlim([x[:, 0].min()-0.5, x[:, 0].max()+0.5])\n",
    "plt.ylim([x[:, 1].min()-0.5, x[:, 1].max()+0.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2-Regularized Logistic Regression via `weight_decay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Train ACC: 0.973 | Cost: 0.055\n",
      "Epoch: 002 | Train ACC: 0.973 | Cost: 0.065\n",
      "Epoch: 003 | Train ACC: 0.973 | Cost: 0.080\n",
      "Epoch: 004 | Train ACC: 0.973 | Cost: 0.094\n",
      "Epoch: 005 | Train ACC: 0.973 | Cost: 0.104\n",
      "Epoch: 006 | Train ACC: 0.973 | Cost: 0.108\n",
      "Epoch: 007 | Train ACC: 0.973 | Cost: 0.110\n",
      "Epoch: 008 | Train ACC: 0.973 | Cost: 0.111\n",
      "Epoch: 009 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 010 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 011 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 012 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 013 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 014 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 015 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 016 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 017 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 018 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 019 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 020 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 021 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 022 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 023 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 024 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 025 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 026 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 027 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 028 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 029 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 030 | Train ACC: 0.973 | Cost: 0.112\n",
      "\n",
      "Model parameters:\n",
      "  Weights: Parameter containing:\n",
      "tensor([[1.7546, 1.5997]], requires_grad=True)\n",
      "  Bias: Parameter containing:\n",
      "tensor([-0.0401], requires_grad=True)\n",
      "\n",
      "\n",
      "Test set accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "def custom_where(cond, x_1, x_2):\n",
    "    return (cond * x_1) + ((1-cond) * x_2)\n",
    "\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(num_features, 1)\n",
    "        # initialize weights to zeros here,\n",
    "        # since we used zero weights in the\n",
    "        # manual approach\n",
    "        \n",
    "        self.linear.weight.detach().zero_()\n",
    "        self.linear.bias.detach().zero_()\n",
    "        # Note: the trailing underscore\n",
    "        # means \"in-place operation\" in the context\n",
    "        # of PyTorch\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        probas = torch.sigmoid(logits)\n",
    "        return probas\n",
    "\n",
    "model = LogisticRegression(num_features=2).to(device)\n",
    "\n",
    "#########################################################\n",
    "## Apply L2 regularization\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=0.1, \n",
    "                            weight_decay=LAMBDA)\n",
    "#-------------------------------------------------------\n",
    "\n",
    "\n",
    "def comp_accuracy(label_var, pred_probas):\n",
    "    pred_labels = custom_where((pred_probas > 0.5).float(), 1, 0).view(-1)\n",
    "    acc = torch.sum(pred_labels == label_var.view(-1)).float() / label_var.size(0)\n",
    "    return acc\n",
    "\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #### Compute outputs ####\n",
    "    out = model(X_train_tensor)\n",
    "    \n",
    "    #### Compute gradients ####\n",
    "    cost = F.binary_cross_entropy(out, y_train_tensor, reduction='sum')\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    \n",
    "    #### Update weights ####  \n",
    "    optimizer.step()\n",
    "    \n",
    "    #### Logging ####      \n",
    "    pred_probas = model(X_train_tensor)\n",
    "    acc = comp_accuracy(y_train_tensor, pred_probas)\n",
    "    print('Epoch: %03d' % (epoch + 1), end=\"\")\n",
    "    print(' | Train ACC: %.3f' % acc, end=\"\")\n",
    "    print(' | Cost: %.3f' % F.binary_cross_entropy(pred_probas, y_train_tensor))\n",
    "\n",
    "\n",
    "    \n",
    "print('\\nModel parameters:')\n",
    "print('  Weights: %s' % model.linear.weight)\n",
    "print('  Bias: %s' % model.linear.bias)\n",
    "\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=device)\n",
    "\n",
    "pred_probas = model(X_test_tensor)\n",
    "test_acc = comp_accuracy(y_test_tensor, pred_probas)\n",
    "\n",
    "print('\\n\\nTest set accuracy: %.2f%%' % (test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2-Regularized Logistic Regression via Manual Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Train ACC: 0.973 | Cost: 0.055\n",
      "Epoch: 002 | Train ACC: 0.973 | Cost: 0.065\n",
      "Epoch: 003 | Train ACC: 0.973 | Cost: 0.080\n",
      "Epoch: 004 | Train ACC: 0.973 | Cost: 0.094\n",
      "Epoch: 005 | Train ACC: 0.973 | Cost: 0.104\n",
      "Epoch: 006 | Train ACC: 0.973 | Cost: 0.108\n",
      "Epoch: 007 | Train ACC: 0.973 | Cost: 0.110\n",
      "Epoch: 008 | Train ACC: 0.973 | Cost: 0.111\n",
      "Epoch: 009 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 010 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 011 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 012 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 013 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 014 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 015 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 016 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 017 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 018 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 019 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 020 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 021 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 022 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 023 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 024 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 025 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 026 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 027 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 028 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 029 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 030 | Train ACC: 0.973 | Cost: 0.112\n",
      "\n",
      "Model parameters:\n",
      "  Weights: Parameter containing:\n",
      "tensor([[1.7546, 1.5997]], requires_grad=True)\n",
      "  Bias: Parameter containing:\n",
      "tensor([-0.0401], requires_grad=True)\n",
      "\n",
      "\n",
      "Test set accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(num_features=2).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #### Compute outputs ####\n",
    "    out = model(X_train_tensor)\n",
    "    \n",
    "    #### Compute gradients ####\n",
    "    \n",
    "    #########################################################\n",
    "    ## Apply L2 regularization (weight decay)\n",
    "    cost = F.binary_cross_entropy(out, y_train_tensor, reduction='sum')\n",
    "    cost = cost + 0.5 * LAMBDA * torch.mm(model.linear.weight,\n",
    "                                          model.linear.weight.t())\n",
    "    \n",
    "    # note that PyTorch also regularizes the bias, hence, if we want\n",
    "    # to reproduce the behavior of SGD's \"weight_decay\" param, we have to add\n",
    "    # the bias term as well: \n",
    "    cost = cost + 0.5 * LAMBDA * model.linear.bias**2\n",
    "    #-------------------------------------------------------\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    \n",
    "    #### Update weights ####  \n",
    "    optimizer.step()\n",
    "    \n",
    "    #### Logging ####      \n",
    "    pred_probas = model(X_train_tensor)\n",
    "    acc = comp_accuracy(y_train_tensor, pred_probas)\n",
    "    print('Epoch: %03d' % (epoch + 1), end=\"\")\n",
    "    print(' | Train ACC: %.3f' % acc, end=\"\")\n",
    "    print(' | Cost: %.3f' % F.binary_cross_entropy(pred_probas, y_train_tensor))\n",
    "\n",
    "\n",
    "    \n",
    "print('\\nModel parameters:')\n",
    "print('  Weights: %s' % model.linear.weight)\n",
    "print('  Bias: %s' % model.linear.bias)\n",
    "\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=device)\n",
    "\n",
    "pred_probas = model(X_test_tensor)\n",
    "test_acc = comp_accuracy(y_test_tensor, pred_probas)\n",
    "\n",
    "print('\\n\\nTest set accuracy: %.2f%%' % (test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: for easier comparison we plotted the regular cost, not the regularized cost (strictly, plotting the regularized cost is more useful as the regular ost may not always go down while making \"progress\")**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
