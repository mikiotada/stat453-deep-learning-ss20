{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 453: Deep Learning (Spring 2020)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2020/  \n",
    "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.7.3\n",
      "IPython 7.9.0\n",
      "\n",
      "torch 1.4.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Runs on CPU or GPU (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional GAN (Not Great)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "random_seed = 42\n",
    "generator_learning_rate = 0.0001\n",
    "discriminator_learning_rate = 0.0001\n",
    "num_epochs = 100\n",
    "BATCH_SIZE = 128\n",
    "LATENT_DIM = 100\n",
    "IMG_SHAPE = (1, 28, 28)\n",
    "IMG_SIZE = 1\n",
    "for x in IMG_SHAPE:\n",
    "    IMG_SIZE *= x\n",
    "\n",
    "\n",
    "\n",
    "##########################\n",
    "### MNIST DATASET\n",
    "##########################\n",
    "\n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=4,\n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class Reshape1(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), 16, 7, 7)\n",
    "\n",
    "\n",
    "class GAN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GAN, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.generator = nn.Sequential(\n",
    "              \n",
    "            nn.Linear(LATENT_DIM, 784),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            Reshape1(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=16, kernel_size=(2, 2), stride=(2, 2), padding=0),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=16, out_channels=8, padding=1, kernel_size=(2, 2)),\n",
    "            nn.LeakyReLU(inplace=True),      \n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=8, kernel_size=(3, 3), stride=(2, 2), padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=8, out_channels=4, padding=1, kernel_size=(3, 3)),\n",
    "            nn.LeakyReLU(inplace=True),    \n",
    "            \n",
    "            nn.Conv2d(in_channels=4, out_channels=1, padding=0, kernel_size=(2, 2)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, padding=1, kernel_size=(3, 3)),\n",
    "            nn.LeakyReLU(inplace=True), \n",
    "            nn.Conv2d(in_channels=8, out_channels=8, padding=1, stride=2, kernel_size=(3, 3)),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            \n",
    "            \n",
    "            nn.Conv2d(in_channels=8, out_channels=16, padding=1, kernel_size=(3, 3)),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, padding=1, stride=2, kernel_size=(3, 3)),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=16, out_channels=32, padding=1, kernel_size=(3, 3)),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, padding=1, stride=2, kernel_size=(3, 3)),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            \n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            Flatten(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "            \n",
    "    def generator_forward(self, z):\n",
    "        img = self.generator(z)\n",
    "        return img\n",
    "    \n",
    "    def discriminator_forward(self, img):\n",
    "        pred = model.discriminator(img)\n",
    "        return pred.view(-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN(\n",
      "  (generator): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=784, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (2): Reshape1()\n",
      "    (3): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (4): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (5): Conv2d(16, 8, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (6): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (7): ConvTranspose2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (9): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (11): Conv2d(4, 1, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (12): Tanh()\n",
      "  )\n",
      "  (discriminator): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (7): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (12): AdaptiveAvgPool2d(output_size=1)\n",
      "    (13): Flatten()\n",
      "    (14): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (15): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (16): Linear(in_features=16, out_features=1, bias=True)\n",
      "    (17): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "\n",
    "#del model\n",
    "model = GAN()\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noutputs = []\\ndef hook(module, input, output):\\n    outputs.append(output)\\n\\n#for i, layer in enumerate(model.discriminator):\\n#    if isinstance(layer, torch.nn.modules.conv.Conv2d):\\n#        model.discriminator[i].register_forward_hook(hook)\\n\\nfor i, layer in enumerate(model.generator):\\n    if isinstance(layer, torch.nn.modules.conv.Conv2d):\\n        model.generator[i].register_forward_hook(hook)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ## FOR DEBUGGING\n",
    "\n",
    "\"\"\"\n",
    "outputs = []\n",
    "def hook(module, input, output):\n",
    "    outputs.append(output)\n",
    "\n",
    "#for i, layer in enumerate(model.discriminator):\n",
    "#    if isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
    "#        model.discriminator[i].register_forward_hook(hook)\n",
    "\n",
    "for i, layer in enumerate(model.generator):\n",
    "    if isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
    "        model.generator[i].register_forward_hook(hook)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_gener = torch.optim.Adam(model.generator.parameters(), lr=generator_learning_rate)\n",
    "optim_discr = torch.optim.Adam(model.discriminator.parameters(), lr=discriminator_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/100 | Batch 000/469 | Gen/Dis Loss: 0.8464/0.7032\n",
      "Epoch: 001/100 | Batch 100/469 | Gen/Dis Loss: 0.8395/0.6160\n",
      "Epoch: 001/100 | Batch 200/469 | Gen/Dis Loss: 1.3425/0.1537\n",
      "Epoch: 001/100 | Batch 300/469 | Gen/Dis Loss: 5.1525/0.0032\n",
      "Epoch: 001/100 | Batch 400/469 | Gen/Dis Loss: 6.4411/0.0009\n",
      "Time elapsed: 0.17 min\n",
      "Epoch: 002/100 | Batch 000/469 | Gen/Dis Loss: 6.9657/0.0005\n",
      "Epoch: 002/100 | Batch 100/469 | Gen/Dis Loss: 7.5284/0.0003\n",
      "Epoch: 002/100 | Batch 200/469 | Gen/Dis Loss: 7.9472/0.0002\n",
      "Epoch: 002/100 | Batch 300/469 | Gen/Dis Loss: 8.0842/0.0002\n",
      "Epoch: 002/100 | Batch 400/469 | Gen/Dis Loss: 7.7919/0.0002\n",
      "Time elapsed: 0.33 min\n",
      "Epoch: 003/100 | Batch 000/469 | Gen/Dis Loss: 2.4400/0.0704\n",
      "Epoch: 003/100 | Batch 100/469 | Gen/Dis Loss: 4.7263/0.0049\n",
      "Epoch: 003/100 | Batch 200/469 | Gen/Dis Loss: 6.6511/0.0101\n",
      "Epoch: 003/100 | Batch 300/469 | Gen/Dis Loss: 6.4032/0.0014\n",
      "Epoch: 003/100 | Batch 400/469 | Gen/Dis Loss: 6.4333/0.0009\n",
      "Time elapsed: 0.50 min\n",
      "Epoch: 004/100 | Batch 000/469 | Gen/Dis Loss: 7.3184/0.0005\n",
      "Epoch: 004/100 | Batch 100/469 | Gen/Dis Loss: 8.4277/0.0008\n",
      "Epoch: 004/100 | Batch 200/469 | Gen/Dis Loss: 7.7713/0.0002\n",
      "Epoch: 004/100 | Batch 300/469 | Gen/Dis Loss: 8.1773/0.0030\n",
      "Epoch: 004/100 | Batch 400/469 | Gen/Dis Loss: 8.0796/0.0002\n",
      "Time elapsed: 0.66 min\n",
      "Epoch: 005/100 | Batch 000/469 | Gen/Dis Loss: 8.3982/0.0003\n",
      "Epoch: 005/100 | Batch 100/469 | Gen/Dis Loss: 8.1634/0.0001\n",
      "Epoch: 005/100 | Batch 200/469 | Gen/Dis Loss: 8.5765/0.0001\n",
      "Epoch: 005/100 | Batch 300/469 | Gen/Dis Loss: 8.7789/0.0001\n",
      "Epoch: 005/100 | Batch 400/469 | Gen/Dis Loss: 7.3540/0.0003\n",
      "Time elapsed: 0.82 min\n",
      "Epoch: 006/100 | Batch 000/469 | Gen/Dis Loss: 7.5331/0.0003\n",
      "Epoch: 006/100 | Batch 100/469 | Gen/Dis Loss: 9.2860/0.0001\n",
      "Epoch: 006/100 | Batch 200/469 | Gen/Dis Loss: 8.7506/0.0023\n",
      "Epoch: 006/100 | Batch 300/469 | Gen/Dis Loss: 8.0391/0.0002\n",
      "Epoch: 006/100 | Batch 400/469 | Gen/Dis Loss: 8.4272/0.0001\n",
      "Time elapsed: 0.99 min\n",
      "Epoch: 007/100 | Batch 000/469 | Gen/Dis Loss: 7.9430/0.0002\n",
      "Epoch: 007/100 | Batch 100/469 | Gen/Dis Loss: 8.1040/0.0002\n",
      "Epoch: 007/100 | Batch 200/469 | Gen/Dis Loss: 8.7303/0.0001\n",
      "Epoch: 007/100 | Batch 300/469 | Gen/Dis Loss: 9.0125/0.0001\n",
      "Epoch: 007/100 | Batch 400/469 | Gen/Dis Loss: 7.2239/0.0331\n",
      "Time elapsed: 1.15 min\n",
      "Epoch: 008/100 | Batch 000/469 | Gen/Dis Loss: 4.7333/0.0050\n",
      "Epoch: 008/100 | Batch 100/469 | Gen/Dis Loss: 5.1805/0.0049\n",
      "Epoch: 008/100 | Batch 200/469 | Gen/Dis Loss: 5.0979/0.0085\n",
      "Epoch: 008/100 | Batch 300/469 | Gen/Dis Loss: 5.8387/0.0079\n",
      "Epoch: 008/100 | Batch 400/469 | Gen/Dis Loss: 5.5824/0.0025\n",
      "Time elapsed: 1.32 min\n",
      "Epoch: 009/100 | Batch 000/469 | Gen/Dis Loss: 6.2086/0.0340\n",
      "Epoch: 009/100 | Batch 100/469 | Gen/Dis Loss: 5.6378/0.0096\n",
      "Epoch: 009/100 | Batch 200/469 | Gen/Dis Loss: 6.6306/0.0120\n",
      "Epoch: 009/100 | Batch 300/469 | Gen/Dis Loss: 5.4879/0.0024\n",
      "Epoch: 009/100 | Batch 400/469 | Gen/Dis Loss: 6.8837/0.0012\n",
      "Time elapsed: 1.48 min\n",
      "Epoch: 010/100 | Batch 000/469 | Gen/Dis Loss: 6.0147/0.0014\n",
      "Epoch: 010/100 | Batch 100/469 | Gen/Dis Loss: 6.7942/0.0007\n",
      "Epoch: 010/100 | Batch 200/469 | Gen/Dis Loss: 6.8284/0.0088\n",
      "Epoch: 010/100 | Batch 300/469 | Gen/Dis Loss: 8.3443/0.0006\n",
      "Epoch: 010/100 | Batch 400/469 | Gen/Dis Loss: 8.1789/0.0002\n",
      "Time elapsed: 1.64 min\n",
      "Epoch: 011/100 | Batch 000/469 | Gen/Dis Loss: 5.5331/0.0020\n",
      "Epoch: 011/100 | Batch 100/469 | Gen/Dis Loss: 6.9445/0.0011\n",
      "Epoch: 011/100 | Batch 200/469 | Gen/Dis Loss: 8.8383/0.0001\n",
      "Epoch: 011/100 | Batch 300/469 | Gen/Dis Loss: 6.5533/0.0009\n",
      "Epoch: 011/100 | Batch 400/469 | Gen/Dis Loss: 8.0027/0.0002\n",
      "Time elapsed: 1.81 min\n",
      "Epoch: 012/100 | Batch 000/469 | Gen/Dis Loss: 6.9510/0.0005\n",
      "Epoch: 012/100 | Batch 100/469 | Gen/Dis Loss: 7.9228/0.0002\n",
      "Epoch: 012/100 | Batch 200/469 | Gen/Dis Loss: 8.4672/0.0001\n",
      "Epoch: 012/100 | Batch 300/469 | Gen/Dis Loss: 5.7532/0.0016\n",
      "Epoch: 012/100 | Batch 400/469 | Gen/Dis Loss: 8.5324/0.0004\n",
      "Time elapsed: 1.97 min\n",
      "Epoch: 013/100 | Batch 000/469 | Gen/Dis Loss: 7.7192/0.0243\n",
      "Epoch: 013/100 | Batch 100/469 | Gen/Dis Loss: 2.8089/0.1562\n",
      "Epoch: 013/100 | Batch 200/469 | Gen/Dis Loss: 0.7398/0.6714\n",
      "Epoch: 013/100 | Batch 300/469 | Gen/Dis Loss: 0.9470/0.4820\n",
      "Epoch: 013/100 | Batch 400/469 | Gen/Dis Loss: 2.2099/0.1335\n",
      "Time elapsed: 2.14 min\n",
      "Epoch: 014/100 | Batch 000/469 | Gen/Dis Loss: 3.5457/0.0366\n",
      "Epoch: 014/100 | Batch 100/469 | Gen/Dis Loss: 4.4515/0.0174\n",
      "Epoch: 014/100 | Batch 200/469 | Gen/Dis Loss: 4.7799/0.0106\n",
      "Epoch: 014/100 | Batch 300/469 | Gen/Dis Loss: 5.1587/0.0091\n",
      "Epoch: 014/100 | Batch 400/469 | Gen/Dis Loss: 3.4317/0.0432\n",
      "Time elapsed: 2.30 min\n",
      "Epoch: 015/100 | Batch 000/469 | Gen/Dis Loss: 4.3319/0.0124\n",
      "Epoch: 015/100 | Batch 100/469 | Gen/Dis Loss: 4.6942/0.0051\n",
      "Epoch: 015/100 | Batch 200/469 | Gen/Dis Loss: 5.4002/0.0037\n",
      "Epoch: 015/100 | Batch 300/469 | Gen/Dis Loss: 5.9302/0.0027\n",
      "Epoch: 015/100 | Batch 400/469 | Gen/Dis Loss: 6.1959/0.0012\n",
      "Time elapsed: 2.47 min\n",
      "Epoch: 016/100 | Batch 000/469 | Gen/Dis Loss: 6.3504/0.0011\n",
      "Epoch: 016/100 | Batch 100/469 | Gen/Dis Loss: 6.6593/0.0010\n",
      "Epoch: 016/100 | Batch 200/469 | Gen/Dis Loss: 6.9572/0.0011\n",
      "Epoch: 016/100 | Batch 300/469 | Gen/Dis Loss: 6.7548/0.0007\n",
      "Epoch: 016/100 | Batch 400/469 | Gen/Dis Loss: 7.0103/0.0005\n",
      "Time elapsed: 2.63 min\n",
      "Epoch: 017/100 | Batch 000/469 | Gen/Dis Loss: 6.8136/0.0006\n",
      "Epoch: 017/100 | Batch 100/469 | Gen/Dis Loss: 6.6860/0.0007\n",
      "Epoch: 017/100 | Batch 200/469 | Gen/Dis Loss: 7.3572/0.0005\n",
      "Epoch: 017/100 | Batch 300/469 | Gen/Dis Loss: 7.9354/0.0021\n",
      "Epoch: 017/100 | Batch 400/469 | Gen/Dis Loss: 7.9231/0.0002\n",
      "Time elapsed: 2.80 min\n",
      "Epoch: 018/100 | Batch 000/469 | Gen/Dis Loss: 8.1221/0.0004\n",
      "Epoch: 018/100 | Batch 100/469 | Gen/Dis Loss: 7.6315/0.0003\n",
      "Epoch: 018/100 | Batch 200/469 | Gen/Dis Loss: 8.3357/0.0003\n",
      "Epoch: 018/100 | Batch 300/469 | Gen/Dis Loss: 8.0500/0.0002\n",
      "Epoch: 018/100 | Batch 400/469 | Gen/Dis Loss: 8.4030/0.0001\n",
      "Time elapsed: 2.96 min\n",
      "Epoch: 019/100 | Batch 000/469 | Gen/Dis Loss: 8.2382/0.0001\n",
      "Epoch: 019/100 | Batch 100/469 | Gen/Dis Loss: 9.0500/0.0001\n",
      "Epoch: 019/100 | Batch 200/469 | Gen/Dis Loss: 8.4906/0.0001\n",
      "Epoch: 019/100 | Batch 300/469 | Gen/Dis Loss: 8.0348/0.0002\n",
      "Epoch: 019/100 | Batch 400/469 | Gen/Dis Loss: 8.1636/0.0001\n",
      "Time elapsed: 3.13 min\n",
      "Epoch: 020/100 | Batch 000/469 | Gen/Dis Loss: 9.1649/0.0001\n",
      "Epoch: 020/100 | Batch 100/469 | Gen/Dis Loss: 9.1149/0.0001\n",
      "Epoch: 020/100 | Batch 200/469 | Gen/Dis Loss: 8.2897/0.0001\n",
      "Epoch: 020/100 | Batch 300/469 | Gen/Dis Loss: 9.5756/0.0000\n",
      "Epoch: 020/100 | Batch 400/469 | Gen/Dis Loss: 9.8187/0.0000\n",
      "Time elapsed: 3.29 min\n",
      "Epoch: 021/100 | Batch 000/469 | Gen/Dis Loss: 10.3179/0.0000\n",
      "Epoch: 021/100 | Batch 100/469 | Gen/Dis Loss: 10.0306/0.0000\n",
      "Epoch: 021/100 | Batch 200/469 | Gen/Dis Loss: 9.5720/0.0000\n",
      "Epoch: 021/100 | Batch 300/469 | Gen/Dis Loss: 10.2696/0.0000\n",
      "Epoch: 021/100 | Batch 400/469 | Gen/Dis Loss: 9.5272/0.0000\n",
      "Time elapsed: 3.46 min\n",
      "Epoch: 022/100 | Batch 000/469 | Gen/Dis Loss: 9.7169/0.0000\n",
      "Epoch: 022/100 | Batch 100/469 | Gen/Dis Loss: 10.0746/0.0000\n",
      "Epoch: 022/100 | Batch 200/469 | Gen/Dis Loss: 10.5956/0.0000\n",
      "Epoch: 022/100 | Batch 300/469 | Gen/Dis Loss: 10.3076/0.0000\n",
      "Epoch: 022/100 | Batch 400/469 | Gen/Dis Loss: 8.0709/0.0002\n",
      "Time elapsed: 3.62 min\n",
      "Epoch: 023/100 | Batch 000/469 | Gen/Dis Loss: 10.4277/0.0000\n",
      "Epoch: 023/100 | Batch 100/469 | Gen/Dis Loss: 10.9582/0.0000\n",
      "Epoch: 023/100 | Batch 200/469 | Gen/Dis Loss: 8.8511/0.0001\n",
      "Epoch: 023/100 | Batch 300/469 | Gen/Dis Loss: 10.4016/0.0000\n",
      "Epoch: 023/100 | Batch 400/469 | Gen/Dis Loss: 10.9812/0.0003\n",
      "Time elapsed: 3.78 min\n",
      "Epoch: 024/100 | Batch 000/469 | Gen/Dis Loss: 11.0945/0.0000\n",
      "Epoch: 024/100 | Batch 100/469 | Gen/Dis Loss: 11.1993/0.0000\n",
      "Epoch: 024/100 | Batch 200/469 | Gen/Dis Loss: 10.3557/0.0000\n",
      "Epoch: 024/100 | Batch 300/469 | Gen/Dis Loss: 11.1137/0.0000\n",
      "Epoch: 024/100 | Batch 400/469 | Gen/Dis Loss: 11.5733/0.0000\n",
      "Time elapsed: 3.95 min\n",
      "Epoch: 025/100 | Batch 000/469 | Gen/Dis Loss: 11.6699/0.0000\n",
      "Epoch: 025/100 | Batch 100/469 | Gen/Dis Loss: 11.5217/0.0000\n",
      "Epoch: 025/100 | Batch 200/469 | Gen/Dis Loss: 11.4044/0.0000\n",
      "Epoch: 025/100 | Batch 300/469 | Gen/Dis Loss: 11.7144/0.0000\n",
      "Epoch: 025/100 | Batch 400/469 | Gen/Dis Loss: 11.0781/0.0000\n",
      "Time elapsed: 4.11 min\n",
      "Epoch: 026/100 | Batch 000/469 | Gen/Dis Loss: 11.2234/0.0000\n",
      "Epoch: 026/100 | Batch 100/469 | Gen/Dis Loss: 11.6669/0.0000\n",
      "Epoch: 026/100 | Batch 200/469 | Gen/Dis Loss: 11.7727/0.0000\n",
      "Epoch: 026/100 | Batch 300/469 | Gen/Dis Loss: 11.8793/0.0000\n",
      "Epoch: 026/100 | Batch 400/469 | Gen/Dis Loss: 12.4312/0.0000\n",
      "Time elapsed: 4.28 min\n",
      "Epoch: 027/100 | Batch 000/469 | Gen/Dis Loss: 10.9775/0.0000\n",
      "Epoch: 027/100 | Batch 100/469 | Gen/Dis Loss: 9.5541/0.0000\n",
      "Epoch: 027/100 | Batch 200/469 | Gen/Dis Loss: 11.9045/0.0000\n",
      "Epoch: 027/100 | Batch 300/469 | Gen/Dis Loss: 12.3088/0.0000\n",
      "Epoch: 027/100 | Batch 400/469 | Gen/Dis Loss: 12.3805/0.0000\n",
      "Time elapsed: 4.44 min\n",
      "Epoch: 028/100 | Batch 000/469 | Gen/Dis Loss: 12.2709/0.0000\n",
      "Epoch: 028/100 | Batch 100/469 | Gen/Dis Loss: 12.4545/0.0000\n",
      "Epoch: 028/100 | Batch 200/469 | Gen/Dis Loss: 10.9263/0.0000\n",
      "Epoch: 028/100 | Batch 300/469 | Gen/Dis Loss: 12.4090/0.0000\n",
      "Epoch: 028/100 | Batch 400/469 | Gen/Dis Loss: 12.6465/0.0000\n",
      "Time elapsed: 4.61 min\n",
      "Epoch: 029/100 | Batch 000/469 | Gen/Dis Loss: 12.5244/0.0000\n",
      "Epoch: 029/100 | Batch 100/469 | Gen/Dis Loss: 12.6779/0.0000\n",
      "Epoch: 029/100 | Batch 200/469 | Gen/Dis Loss: 12.6188/0.0000\n",
      "Epoch: 029/100 | Batch 300/469 | Gen/Dis Loss: 12.7735/0.0000\n",
      "Epoch: 029/100 | Batch 400/469 | Gen/Dis Loss: 12.3025/0.0000\n",
      "Time elapsed: 4.77 min\n",
      "Epoch: 030/100 | Batch 000/469 | Gen/Dis Loss: 12.6532/0.0000\n",
      "Epoch: 030/100 | Batch 100/469 | Gen/Dis Loss: 12.9918/0.0000\n",
      "Epoch: 030/100 | Batch 200/469 | Gen/Dis Loss: 11.3927/0.0000\n",
      "Epoch: 030/100 | Batch 300/469 | Gen/Dis Loss: 13.0473/0.0000\n",
      "Epoch: 030/100 | Batch 400/469 | Gen/Dis Loss: 13.3520/0.0000\n",
      "Time elapsed: 4.94 min\n",
      "Epoch: 031/100 | Batch 000/469 | Gen/Dis Loss: 10.6852/0.0000\n",
      "Epoch: 031/100 | Batch 100/469 | Gen/Dis Loss: 13.1992/0.0000\n",
      "Epoch: 031/100 | Batch 200/469 | Gen/Dis Loss: 13.4640/0.0000\n",
      "Epoch: 031/100 | Batch 300/469 | Gen/Dis Loss: 12.9394/0.0000\n",
      "Epoch: 031/100 | Batch 400/469 | Gen/Dis Loss: 13.0947/0.0000\n",
      "Time elapsed: 5.11 min\n",
      "Epoch: 032/100 | Batch 000/469 | Gen/Dis Loss: 12.9513/0.1998\n",
      "Epoch: 032/100 | Batch 100/469 | Gen/Dis Loss: 5.9208/0.0544\n",
      "Epoch: 032/100 | Batch 200/469 | Gen/Dis Loss: 6.2141/0.1298\n",
      "Epoch: 032/100 | Batch 300/469 | Gen/Dis Loss: 5.2532/0.1040\n",
      "Epoch: 032/100 | Batch 400/469 | Gen/Dis Loss: 5.7250/0.0485\n",
      "Time elapsed: 5.27 min\n",
      "Epoch: 033/100 | Batch 000/469 | Gen/Dis Loss: 6.8341/0.0337\n",
      "Epoch: 033/100 | Batch 100/469 | Gen/Dis Loss: 6.2401/0.0215\n",
      "Epoch: 033/100 | Batch 200/469 | Gen/Dis Loss: 6.8297/0.0205\n",
      "Epoch: 033/100 | Batch 300/469 | Gen/Dis Loss: 6.2356/0.0310\n",
      "Epoch: 033/100 | Batch 400/469 | Gen/Dis Loss: 5.9481/0.0145\n",
      "Time elapsed: 5.44 min\n",
      "Epoch: 034/100 | Batch 000/469 | Gen/Dis Loss: 6.2481/0.0086\n",
      "Epoch: 034/100 | Batch 100/469 | Gen/Dis Loss: 6.7742/0.0066\n",
      "Epoch: 034/100 | Batch 200/469 | Gen/Dis Loss: 6.7751/0.0118\n",
      "Epoch: 034/100 | Batch 300/469 | Gen/Dis Loss: 7.1814/0.0011\n",
      "Epoch: 034/100 | Batch 400/469 | Gen/Dis Loss: 7.2669/0.0055\n",
      "Time elapsed: 5.60 min\n",
      "Epoch: 035/100 | Batch 000/469 | Gen/Dis Loss: 6.3639/0.0063\n",
      "Epoch: 035/100 | Batch 100/469 | Gen/Dis Loss: 6.8092/0.0027\n",
      "Epoch: 035/100 | Batch 200/469 | Gen/Dis Loss: 6.9658/0.0012\n",
      "Epoch: 035/100 | Batch 300/469 | Gen/Dis Loss: 7.7816/0.0007\n",
      "Epoch: 035/100 | Batch 400/469 | Gen/Dis Loss: 7.4720/0.0010\n",
      "Time elapsed: 5.77 min\n",
      "Epoch: 036/100 | Batch 000/469 | Gen/Dis Loss: 7.2315/0.0025\n",
      "Epoch: 036/100 | Batch 100/469 | Gen/Dis Loss: 7.8964/0.0033\n",
      "Epoch: 036/100 | Batch 200/469 | Gen/Dis Loss: 6.7785/0.0015\n",
      "Epoch: 036/100 | Batch 300/469 | Gen/Dis Loss: 7.1331/0.0010\n",
      "Epoch: 036/100 | Batch 400/469 | Gen/Dis Loss: 7.8799/0.0005\n",
      "Time elapsed: 5.94 min\n",
      "Epoch: 037/100 | Batch 000/469 | Gen/Dis Loss: 7.8872/0.0004\n",
      "Epoch: 037/100 | Batch 100/469 | Gen/Dis Loss: 7.8175/0.0003\n",
      "Epoch: 037/100 | Batch 200/469 | Gen/Dis Loss: 8.4582/0.0002\n",
      "Epoch: 037/100 | Batch 300/469 | Gen/Dis Loss: 7.7337/0.0004\n",
      "Epoch: 037/100 | Batch 400/469 | Gen/Dis Loss: 8.8669/0.0012\n",
      "Time elapsed: 6.10 min\n",
      "Epoch: 038/100 | Batch 000/469 | Gen/Dis Loss: 8.8196/0.0001\n",
      "Epoch: 038/100 | Batch 100/469 | Gen/Dis Loss: 9.2444/0.0001\n",
      "Epoch: 038/100 | Batch 200/469 | Gen/Dis Loss: 9.8072/0.0000\n",
      "Epoch: 038/100 | Batch 300/469 | Gen/Dis Loss: 8.9892/0.0001\n",
      "Epoch: 038/100 | Batch 400/469 | Gen/Dis Loss: 8.9307/0.0112\n",
      "Time elapsed: 6.27 min\n",
      "Epoch: 039/100 | Batch 000/469 | Gen/Dis Loss: 8.3941/0.0002\n",
      "Epoch: 039/100 | Batch 100/469 | Gen/Dis Loss: 9.0483/0.0001\n",
      "Epoch: 039/100 | Batch 200/469 | Gen/Dis Loss: 9.2871/0.0001\n",
      "Epoch: 039/100 | Batch 300/469 | Gen/Dis Loss: 8.6232/0.0002\n",
      "Epoch: 039/100 | Batch 400/469 | Gen/Dis Loss: 7.2486/0.0006\n",
      "Time elapsed: 6.44 min\n",
      "Epoch: 040/100 | Batch 000/469 | Gen/Dis Loss: 9.6732/0.0000\n",
      "Epoch: 040/100 | Batch 100/469 | Gen/Dis Loss: 9.4839/0.0004\n",
      "Epoch: 040/100 | Batch 200/469 | Gen/Dis Loss: 9.1177/0.0001\n",
      "Epoch: 040/100 | Batch 300/469 | Gen/Dis Loss: 10.2571/0.0000\n",
      "Epoch: 040/100 | Batch 400/469 | Gen/Dis Loss: 9.8440/0.0000\n",
      "Time elapsed: 6.60 min\n",
      "Epoch: 041/100 | Batch 000/469 | Gen/Dis Loss: 9.9181/0.0003\n",
      "Epoch: 041/100 | Batch 100/469 | Gen/Dis Loss: 10.6686/0.0001\n",
      "Epoch: 041/100 | Batch 200/469 | Gen/Dis Loss: 7.9934/0.0013\n",
      "Epoch: 041/100 | Batch 300/469 | Gen/Dis Loss: 8.2316/0.0253\n",
      "Epoch: 041/100 | Batch 400/469 | Gen/Dis Loss: 7.2755/0.0044\n",
      "Time elapsed: 6.77 min\n",
      "Epoch: 042/100 | Batch 000/469 | Gen/Dis Loss: 6.2679/0.0365\n",
      "Epoch: 042/100 | Batch 100/469 | Gen/Dis Loss: 6.1293/0.0621\n",
      "Epoch: 042/100 | Batch 200/469 | Gen/Dis Loss: 7.9667/0.0465\n",
      "Epoch: 042/100 | Batch 300/469 | Gen/Dis Loss: 7.6992/0.0684\n",
      "Epoch: 042/100 | Batch 400/469 | Gen/Dis Loss: 7.6905/0.0502\n",
      "Time elapsed: 6.94 min\n",
      "Epoch: 043/100 | Batch 000/469 | Gen/Dis Loss: 7.2301/0.0803\n",
      "Epoch: 043/100 | Batch 100/469 | Gen/Dis Loss: 4.9486/0.1123\n",
      "Epoch: 043/100 | Batch 200/469 | Gen/Dis Loss: 4.5445/0.0907\n",
      "Epoch: 043/100 | Batch 300/469 | Gen/Dis Loss: 5.9279/0.0377\n",
      "Epoch: 043/100 | Batch 400/469 | Gen/Dis Loss: 5.0161/0.0377\n",
      "Time elapsed: 7.11 min\n",
      "Epoch: 044/100 | Batch 000/469 | Gen/Dis Loss: 6.8301/0.0372\n",
      "Epoch: 044/100 | Batch 100/469 | Gen/Dis Loss: 4.8600/0.0326\n",
      "Epoch: 044/100 | Batch 200/469 | Gen/Dis Loss: 3.9590/0.0985\n",
      "Epoch: 044/100 | Batch 300/469 | Gen/Dis Loss: 4.1571/0.0479\n",
      "Epoch: 044/100 | Batch 400/469 | Gen/Dis Loss: 5.4162/0.0307\n",
      "Time elapsed: 7.28 min\n",
      "Epoch: 045/100 | Batch 000/469 | Gen/Dis Loss: 5.4340/0.0326\n",
      "Epoch: 045/100 | Batch 100/469 | Gen/Dis Loss: 5.0685/0.0555\n",
      "Epoch: 045/100 | Batch 200/469 | Gen/Dis Loss: 4.5771/0.0501\n",
      "Epoch: 045/100 | Batch 300/469 | Gen/Dis Loss: 5.1499/0.0391\n",
      "Epoch: 045/100 | Batch 400/469 | Gen/Dis Loss: 5.7609/0.0354\n",
      "Time elapsed: 7.44 min\n",
      "Epoch: 046/100 | Batch 000/469 | Gen/Dis Loss: 5.6420/0.0792\n",
      "Epoch: 046/100 | Batch 100/469 | Gen/Dis Loss: 4.7520/0.0290\n",
      "Epoch: 046/100 | Batch 200/469 | Gen/Dis Loss: 4.1711/0.0538\n",
      "Epoch: 046/100 | Batch 300/469 | Gen/Dis Loss: 5.0003/0.0561\n",
      "Epoch: 046/100 | Batch 400/469 | Gen/Dis Loss: 5.2550/0.0237\n",
      "Time elapsed: 7.61 min\n",
      "Epoch: 047/100 | Batch 000/469 | Gen/Dis Loss: 4.1684/0.0457\n",
      "Epoch: 047/100 | Batch 100/469 | Gen/Dis Loss: 4.4367/0.0758\n",
      "Epoch: 047/100 | Batch 200/469 | Gen/Dis Loss: 5.0781/0.1098\n",
      "Epoch: 047/100 | Batch 300/469 | Gen/Dis Loss: 3.5004/0.1865\n",
      "Epoch: 047/100 | Batch 400/469 | Gen/Dis Loss: 3.3190/0.1466\n",
      "Time elapsed: 7.78 min\n",
      "Epoch: 048/100 | Batch 000/469 | Gen/Dis Loss: 3.5676/0.1252\n",
      "Epoch: 048/100 | Batch 100/469 | Gen/Dis Loss: 3.1740/0.0910\n",
      "Epoch: 048/100 | Batch 200/469 | Gen/Dis Loss: 2.8673/0.1231\n",
      "Epoch: 048/100 | Batch 300/469 | Gen/Dis Loss: 3.6014/0.0946\n",
      "Epoch: 048/100 | Batch 400/469 | Gen/Dis Loss: 3.4313/0.1056\n",
      "Time elapsed: 7.95 min\n",
      "Epoch: 049/100 | Batch 000/469 | Gen/Dis Loss: 4.1327/0.1462\n",
      "Epoch: 049/100 | Batch 100/469 | Gen/Dis Loss: 3.6587/0.0619\n",
      "Epoch: 049/100 | Batch 200/469 | Gen/Dis Loss: 3.9077/0.1352\n",
      "Epoch: 049/100 | Batch 300/469 | Gen/Dis Loss: 4.3195/0.1020\n",
      "Epoch: 049/100 | Batch 400/469 | Gen/Dis Loss: 2.9419/0.1081\n",
      "Time elapsed: 8.11 min\n",
      "Epoch: 050/100 | Batch 000/469 | Gen/Dis Loss: 3.6554/0.1247\n",
      "Epoch: 050/100 | Batch 100/469 | Gen/Dis Loss: 3.6084/0.0848\n",
      "Epoch: 050/100 | Batch 200/469 | Gen/Dis Loss: 3.3575/0.0720\n",
      "Epoch: 050/100 | Batch 300/469 | Gen/Dis Loss: 3.3361/0.1150\n",
      "Epoch: 050/100 | Batch 400/469 | Gen/Dis Loss: 4.1722/0.1469\n",
      "Time elapsed: 8.28 min\n",
      "Epoch: 051/100 | Batch 000/469 | Gen/Dis Loss: 2.3838/0.1560\n",
      "Epoch: 051/100 | Batch 100/469 | Gen/Dis Loss: 3.5026/0.0957\n",
      "Epoch: 051/100 | Batch 200/469 | Gen/Dis Loss: 3.5053/0.0838\n",
      "Epoch: 051/100 | Batch 300/469 | Gen/Dis Loss: 3.7374/0.1136\n",
      "Epoch: 051/100 | Batch 400/469 | Gen/Dis Loss: 4.4691/0.1085\n",
      "Time elapsed: 8.45 min\n",
      "Epoch: 052/100 | Batch 000/469 | Gen/Dis Loss: 2.8893/0.1156\n",
      "Epoch: 052/100 | Batch 100/469 | Gen/Dis Loss: 3.9996/0.1160\n",
      "Epoch: 052/100 | Batch 200/469 | Gen/Dis Loss: 2.7551/0.1687\n",
      "Epoch: 052/100 | Batch 300/469 | Gen/Dis Loss: 3.7283/0.1336\n",
      "Epoch: 052/100 | Batch 400/469 | Gen/Dis Loss: 2.3626/0.2128\n",
      "Time elapsed: 8.61 min\n",
      "Epoch: 053/100 | Batch 000/469 | Gen/Dis Loss: 3.1544/0.1698\n",
      "Epoch: 053/100 | Batch 100/469 | Gen/Dis Loss: 3.6432/0.2772\n",
      "Epoch: 053/100 | Batch 200/469 | Gen/Dis Loss: 2.5183/0.1630\n",
      "Epoch: 053/100 | Batch 300/469 | Gen/Dis Loss: 3.1993/0.2095\n",
      "Epoch: 053/100 | Batch 400/469 | Gen/Dis Loss: 3.9914/0.1377\n",
      "Time elapsed: 8.78 min\n",
      "Epoch: 054/100 | Batch 000/469 | Gen/Dis Loss: 3.1986/0.1349\n",
      "Epoch: 054/100 | Batch 100/469 | Gen/Dis Loss: 2.4176/0.2367\n",
      "Epoch: 054/100 | Batch 200/469 | Gen/Dis Loss: 2.5145/0.2589\n",
      "Epoch: 054/100 | Batch 300/469 | Gen/Dis Loss: 2.8505/0.2008\n",
      "Epoch: 054/100 | Batch 400/469 | Gen/Dis Loss: 1.7643/0.3305\n",
      "Time elapsed: 8.94 min\n",
      "Epoch: 055/100 | Batch 000/469 | Gen/Dis Loss: 3.0345/0.2714\n",
      "Epoch: 055/100 | Batch 100/469 | Gen/Dis Loss: 3.5694/0.2413\n",
      "Epoch: 055/100 | Batch 200/469 | Gen/Dis Loss: 2.4305/0.2148\n",
      "Epoch: 055/100 | Batch 300/469 | Gen/Dis Loss: 2.5808/0.2893\n",
      "Epoch: 055/100 | Batch 400/469 | Gen/Dis Loss: 3.0267/0.2011\n",
      "Time elapsed: 9.11 min\n",
      "Epoch: 056/100 | Batch 000/469 | Gen/Dis Loss: 3.6913/0.2658\n",
      "Epoch: 056/100 | Batch 100/469 | Gen/Dis Loss: 1.9713/0.3228\n",
      "Epoch: 056/100 | Batch 200/469 | Gen/Dis Loss: 2.8040/0.1785\n",
      "Epoch: 056/100 | Batch 300/469 | Gen/Dis Loss: 2.1975/0.2739\n",
      "Epoch: 056/100 | Batch 400/469 | Gen/Dis Loss: 2.0000/0.3452\n",
      "Time elapsed: 9.28 min\n",
      "Epoch: 057/100 | Batch 000/469 | Gen/Dis Loss: 2.4673/0.2996\n",
      "Epoch: 057/100 | Batch 100/469 | Gen/Dis Loss: 2.7670/0.3585\n",
      "Epoch: 057/100 | Batch 200/469 | Gen/Dis Loss: 2.1128/0.2457\n",
      "Epoch: 057/100 | Batch 300/469 | Gen/Dis Loss: 2.9577/0.3374\n",
      "Epoch: 057/100 | Batch 400/469 | Gen/Dis Loss: 2.6839/0.2728\n",
      "Time elapsed: 9.45 min\n",
      "Epoch: 058/100 | Batch 000/469 | Gen/Dis Loss: 2.7101/0.3090\n",
      "Epoch: 058/100 | Batch 100/469 | Gen/Dis Loss: 2.2601/0.3668\n",
      "Epoch: 058/100 | Batch 200/469 | Gen/Dis Loss: 1.3100/0.3707\n",
      "Epoch: 058/100 | Batch 300/469 | Gen/Dis Loss: 1.8952/0.2512\n",
      "Epoch: 058/100 | Batch 400/469 | Gen/Dis Loss: 2.4375/0.2768\n",
      "Time elapsed: 9.61 min\n",
      "Epoch: 059/100 | Batch 000/469 | Gen/Dis Loss: 2.2274/0.2675\n",
      "Epoch: 059/100 | Batch 100/469 | Gen/Dis Loss: 2.6298/0.3112\n",
      "Epoch: 059/100 | Batch 200/469 | Gen/Dis Loss: 1.7794/0.3106\n",
      "Epoch: 059/100 | Batch 300/469 | Gen/Dis Loss: 1.7302/0.2720\n",
      "Epoch: 059/100 | Batch 400/469 | Gen/Dis Loss: 2.2523/0.2842\n",
      "Time elapsed: 9.78 min\n",
      "Epoch: 060/100 | Batch 000/469 | Gen/Dis Loss: 2.7146/0.2974\n",
      "Epoch: 060/100 | Batch 100/469 | Gen/Dis Loss: 1.9421/0.3076\n",
      "Epoch: 060/100 | Batch 200/469 | Gen/Dis Loss: 2.5360/0.2865\n",
      "Epoch: 060/100 | Batch 300/469 | Gen/Dis Loss: 1.9575/0.2649\n",
      "Epoch: 060/100 | Batch 400/469 | Gen/Dis Loss: 2.2356/0.3178\n",
      "Time elapsed: 9.95 min\n",
      "Epoch: 061/100 | Batch 000/469 | Gen/Dis Loss: 2.6109/0.2916\n",
      "Epoch: 061/100 | Batch 100/469 | Gen/Dis Loss: 1.9390/0.3129\n",
      "Epoch: 061/100 | Batch 200/469 | Gen/Dis Loss: 2.1505/0.2745\n",
      "Epoch: 061/100 | Batch 300/469 | Gen/Dis Loss: 1.7374/0.3468\n",
      "Epoch: 061/100 | Batch 400/469 | Gen/Dis Loss: 1.1549/0.4450\n",
      "Time elapsed: 10.11 min\n",
      "Epoch: 062/100 | Batch 000/469 | Gen/Dis Loss: 2.0401/0.3549\n",
      "Epoch: 062/100 | Batch 100/469 | Gen/Dis Loss: 1.8067/0.3548\n",
      "Epoch: 062/100 | Batch 200/469 | Gen/Dis Loss: 1.6991/0.3977\n",
      "Epoch: 062/100 | Batch 300/469 | Gen/Dis Loss: 1.6469/0.3936\n",
      "Epoch: 062/100 | Batch 400/469 | Gen/Dis Loss: 1.4152/0.4280\n",
      "Time elapsed: 10.28 min\n",
      "Epoch: 063/100 | Batch 000/469 | Gen/Dis Loss: 1.6736/0.3849\n",
      "Epoch: 063/100 | Batch 100/469 | Gen/Dis Loss: 1.4724/0.4065\n",
      "Epoch: 063/100 | Batch 200/469 | Gen/Dis Loss: 1.4905/0.3947\n",
      "Epoch: 063/100 | Batch 300/469 | Gen/Dis Loss: 1.2731/0.4744\n",
      "Epoch: 063/100 | Batch 400/469 | Gen/Dis Loss: 1.5108/0.4797\n",
      "Time elapsed: 10.45 min\n",
      "Epoch: 064/100 | Batch 000/469 | Gen/Dis Loss: 1.3246/0.4621\n",
      "Epoch: 064/100 | Batch 100/469 | Gen/Dis Loss: 1.2254/0.5141\n",
      "Epoch: 064/100 | Batch 200/469 | Gen/Dis Loss: 1.1915/0.4128\n",
      "Epoch: 064/100 | Batch 300/469 | Gen/Dis Loss: 1.3338/0.4224\n",
      "Epoch: 064/100 | Batch 400/469 | Gen/Dis Loss: 1.3323/0.4272\n",
      "Time elapsed: 10.61 min\n",
      "Epoch: 065/100 | Batch 000/469 | Gen/Dis Loss: 0.8592/0.5140\n",
      "Epoch: 065/100 | Batch 100/469 | Gen/Dis Loss: 1.1846/0.4333\n",
      "Epoch: 065/100 | Batch 200/469 | Gen/Dis Loss: 1.7815/0.3812\n",
      "Epoch: 065/100 | Batch 300/469 | Gen/Dis Loss: 1.3231/0.3751\n",
      "Epoch: 065/100 | Batch 400/469 | Gen/Dis Loss: 0.9302/0.4619\n",
      "Time elapsed: 10.78 min\n",
      "Epoch: 066/100 | Batch 000/469 | Gen/Dis Loss: 1.0776/0.4589\n",
      "Epoch: 066/100 | Batch 100/469 | Gen/Dis Loss: 1.7767/0.4114\n",
      "Epoch: 066/100 | Batch 200/469 | Gen/Dis Loss: 1.7552/0.4477\n",
      "Epoch: 066/100 | Batch 300/469 | Gen/Dis Loss: 1.8479/0.4498\n",
      "Epoch: 066/100 | Batch 400/469 | Gen/Dis Loss: 1.2925/0.4198\n",
      "Time elapsed: 10.95 min\n",
      "Epoch: 067/100 | Batch 000/469 | Gen/Dis Loss: 1.6922/0.4676\n",
      "Epoch: 067/100 | Batch 100/469 | Gen/Dis Loss: 1.5467/0.4077\n",
      "Epoch: 067/100 | Batch 200/469 | Gen/Dis Loss: 1.6138/0.4349\n",
      "Epoch: 067/100 | Batch 300/469 | Gen/Dis Loss: 1.3059/0.4466\n",
      "Epoch: 067/100 | Batch 400/469 | Gen/Dis Loss: 1.2581/0.4558\n",
      "Time elapsed: 11.11 min\n",
      "Epoch: 068/100 | Batch 000/469 | Gen/Dis Loss: 1.4093/0.4204\n",
      "Epoch: 068/100 | Batch 100/469 | Gen/Dis Loss: 0.9796/0.4754\n",
      "Epoch: 068/100 | Batch 200/469 | Gen/Dis Loss: 1.2815/0.4540\n",
      "Epoch: 068/100 | Batch 300/469 | Gen/Dis Loss: 1.7253/0.4855\n",
      "Epoch: 068/100 | Batch 400/469 | Gen/Dis Loss: 1.1612/0.4550\n",
      "Time elapsed: 11.28 min\n",
      "Epoch: 069/100 | Batch 000/469 | Gen/Dis Loss: 1.4719/0.4511\n",
      "Epoch: 069/100 | Batch 100/469 | Gen/Dis Loss: 1.9789/0.4540\n",
      "Epoch: 069/100 | Batch 200/469 | Gen/Dis Loss: 1.4315/0.4789\n",
      "Epoch: 069/100 | Batch 300/469 | Gen/Dis Loss: 1.2830/0.4540\n",
      "Epoch: 069/100 | Batch 400/469 | Gen/Dis Loss: 1.3571/0.4863\n",
      "Time elapsed: 11.45 min\n",
      "Epoch: 070/100 | Batch 000/469 | Gen/Dis Loss: 1.4379/0.4352\n",
      "Epoch: 070/100 | Batch 100/469 | Gen/Dis Loss: 1.5289/0.4608\n",
      "Epoch: 070/100 | Batch 200/469 | Gen/Dis Loss: 1.4860/0.4123\n",
      "Epoch: 070/100 | Batch 300/469 | Gen/Dis Loss: 1.0880/0.5114\n",
      "Epoch: 070/100 | Batch 400/469 | Gen/Dis Loss: 1.5136/0.5211\n",
      "Time elapsed: 11.61 min\n",
      "Epoch: 071/100 | Batch 000/469 | Gen/Dis Loss: 1.3897/0.4983\n",
      "Epoch: 071/100 | Batch 100/469 | Gen/Dis Loss: 0.8992/0.5069\n",
      "Epoch: 071/100 | Batch 200/469 | Gen/Dis Loss: 1.5469/0.4962\n",
      "Epoch: 071/100 | Batch 300/469 | Gen/Dis Loss: 1.6272/0.4506\n",
      "Epoch: 071/100 | Batch 400/469 | Gen/Dis Loss: 1.5252/0.5944\n",
      "Time elapsed: 11.78 min\n",
      "Epoch: 072/100 | Batch 000/469 | Gen/Dis Loss: 1.4180/0.4327\n",
      "Epoch: 072/100 | Batch 100/469 | Gen/Dis Loss: 0.9183/0.4786\n",
      "Epoch: 072/100 | Batch 200/469 | Gen/Dis Loss: 0.9837/0.4993\n",
      "Epoch: 072/100 | Batch 300/469 | Gen/Dis Loss: 1.0030/0.4978\n",
      "Epoch: 072/100 | Batch 400/469 | Gen/Dis Loss: 1.4084/0.4603\n",
      "Time elapsed: 11.95 min\n",
      "Epoch: 073/100 | Batch 000/469 | Gen/Dis Loss: 1.6626/0.5109\n",
      "Epoch: 073/100 | Batch 100/469 | Gen/Dis Loss: 1.1268/0.4897\n",
      "Epoch: 073/100 | Batch 200/469 | Gen/Dis Loss: 1.7376/0.4673\n",
      "Epoch: 073/100 | Batch 300/469 | Gen/Dis Loss: 1.3762/0.4878\n",
      "Epoch: 073/100 | Batch 400/469 | Gen/Dis Loss: 1.8787/0.5396\n",
      "Time elapsed: 12.12 min\n",
      "Epoch: 074/100 | Batch 000/469 | Gen/Dis Loss: 1.3443/0.5082\n",
      "Epoch: 074/100 | Batch 100/469 | Gen/Dis Loss: 1.0928/0.4905\n",
      "Epoch: 074/100 | Batch 200/469 | Gen/Dis Loss: 1.5177/0.4524\n",
      "Epoch: 074/100 | Batch 300/469 | Gen/Dis Loss: 1.2064/0.4121\n",
      "Epoch: 074/100 | Batch 400/469 | Gen/Dis Loss: 1.4499/0.4939\n",
      "Time elapsed: 12.28 min\n",
      "Epoch: 075/100 | Batch 000/469 | Gen/Dis Loss: 0.9503/0.5229\n",
      "Epoch: 075/100 | Batch 100/469 | Gen/Dis Loss: 1.4846/0.4831\n",
      "Epoch: 075/100 | Batch 200/469 | Gen/Dis Loss: 1.1160/0.5804\n",
      "Epoch: 075/100 | Batch 300/469 | Gen/Dis Loss: 1.4583/0.4457\n",
      "Epoch: 075/100 | Batch 400/469 | Gen/Dis Loss: 1.1483/0.4404\n",
      "Time elapsed: 12.45 min\n",
      "Epoch: 076/100 | Batch 000/469 | Gen/Dis Loss: 1.0881/0.5068\n",
      "Epoch: 076/100 | Batch 100/469 | Gen/Dis Loss: 1.0404/0.4939\n",
      "Epoch: 076/100 | Batch 200/469 | Gen/Dis Loss: 1.2744/0.5326\n",
      "Epoch: 076/100 | Batch 300/469 | Gen/Dis Loss: 1.2595/0.5155\n",
      "Epoch: 076/100 | Batch 400/469 | Gen/Dis Loss: 1.0607/0.4519\n",
      "Time elapsed: 12.62 min\n",
      "Epoch: 077/100 | Batch 000/469 | Gen/Dis Loss: 1.2144/0.5114\n",
      "Epoch: 077/100 | Batch 100/469 | Gen/Dis Loss: 1.2196/0.4668\n",
      "Epoch: 077/100 | Batch 200/469 | Gen/Dis Loss: 1.2429/0.4727\n",
      "Epoch: 077/100 | Batch 300/469 | Gen/Dis Loss: 1.0126/0.5550\n",
      "Epoch: 077/100 | Batch 400/469 | Gen/Dis Loss: 1.2046/0.5097\n",
      "Time elapsed: 12.79 min\n",
      "Epoch: 078/100 | Batch 000/469 | Gen/Dis Loss: 1.1759/0.5291\n",
      "Epoch: 078/100 | Batch 100/469 | Gen/Dis Loss: 1.1160/0.5022\n",
      "Epoch: 078/100 | Batch 200/469 | Gen/Dis Loss: 0.7197/0.6156\n",
      "Epoch: 078/100 | Batch 300/469 | Gen/Dis Loss: 1.4556/0.4750\n",
      "Epoch: 078/100 | Batch 400/469 | Gen/Dis Loss: 1.2364/0.5321\n",
      "Time elapsed: 12.95 min\n",
      "Epoch: 079/100 | Batch 000/469 | Gen/Dis Loss: 1.0593/0.5884\n",
      "Epoch: 079/100 | Batch 100/469 | Gen/Dis Loss: 1.2498/0.4955\n",
      "Epoch: 079/100 | Batch 200/469 | Gen/Dis Loss: 0.9846/0.5898\n",
      "Epoch: 079/100 | Batch 300/469 | Gen/Dis Loss: 0.8144/0.5214\n",
      "Epoch: 079/100 | Batch 400/469 | Gen/Dis Loss: 1.3298/0.6057\n",
      "Time elapsed: 13.12 min\n",
      "Epoch: 080/100 | Batch 000/469 | Gen/Dis Loss: 1.2634/0.5566\n",
      "Epoch: 080/100 | Batch 100/469 | Gen/Dis Loss: 1.1083/0.6582\n",
      "Epoch: 080/100 | Batch 200/469 | Gen/Dis Loss: 1.3112/0.5463\n",
      "Epoch: 080/100 | Batch 300/469 | Gen/Dis Loss: 1.2167/0.5637\n",
      "Epoch: 080/100 | Batch 400/469 | Gen/Dis Loss: 1.0034/0.5693\n",
      "Time elapsed: 13.29 min\n",
      "Epoch: 081/100 | Batch 000/469 | Gen/Dis Loss: 1.2989/0.5225\n",
      "Epoch: 081/100 | Batch 100/469 | Gen/Dis Loss: 1.0284/0.6161\n",
      "Epoch: 081/100 | Batch 200/469 | Gen/Dis Loss: 1.1840/0.5980\n",
      "Epoch: 081/100 | Batch 300/469 | Gen/Dis Loss: 1.1149/0.5589\n",
      "Epoch: 081/100 | Batch 400/469 | Gen/Dis Loss: 1.0905/0.5112\n",
      "Time elapsed: 13.46 min\n",
      "Epoch: 082/100 | Batch 000/469 | Gen/Dis Loss: 0.8149/0.5858\n",
      "Epoch: 082/100 | Batch 100/469 | Gen/Dis Loss: 0.8973/0.5026\n",
      "Epoch: 082/100 | Batch 200/469 | Gen/Dis Loss: 1.0935/0.5453\n",
      "Epoch: 082/100 | Batch 300/469 | Gen/Dis Loss: 1.2530/0.4929\n",
      "Epoch: 082/100 | Batch 400/469 | Gen/Dis Loss: 1.2335/0.5509\n",
      "Time elapsed: 13.62 min\n",
      "Epoch: 083/100 | Batch 000/469 | Gen/Dis Loss: 1.3127/0.5180\n",
      "Epoch: 083/100 | Batch 100/469 | Gen/Dis Loss: 0.9378/0.5322\n",
      "Epoch: 083/100 | Batch 200/469 | Gen/Dis Loss: 0.8230/0.5610\n",
      "Epoch: 083/100 | Batch 300/469 | Gen/Dis Loss: 1.2219/0.5339\n",
      "Epoch: 083/100 | Batch 400/469 | Gen/Dis Loss: 1.3472/0.5513\n",
      "Time elapsed: 13.79 min\n",
      "Epoch: 084/100 | Batch 000/469 | Gen/Dis Loss: 1.1659/0.4975\n",
      "Epoch: 084/100 | Batch 100/469 | Gen/Dis Loss: 1.1690/0.5482\n",
      "Epoch: 084/100 | Batch 200/469 | Gen/Dis Loss: 1.0955/0.5175\n",
      "Epoch: 084/100 | Batch 300/469 | Gen/Dis Loss: 1.0396/0.5191\n",
      "Epoch: 084/100 | Batch 400/469 | Gen/Dis Loss: 1.1073/0.5245\n",
      "Time elapsed: 13.96 min\n",
      "Epoch: 085/100 | Batch 000/469 | Gen/Dis Loss: 1.2408/0.5550\n",
      "Epoch: 085/100 | Batch 100/469 | Gen/Dis Loss: 1.1029/0.5179\n",
      "Epoch: 085/100 | Batch 200/469 | Gen/Dis Loss: 1.2404/0.5524\n",
      "Epoch: 085/100 | Batch 300/469 | Gen/Dis Loss: 1.1757/0.4990\n",
      "Epoch: 085/100 | Batch 400/469 | Gen/Dis Loss: 0.9760/0.4793\n",
      "Time elapsed: 14.13 min\n",
      "Epoch: 086/100 | Batch 000/469 | Gen/Dis Loss: 1.3010/0.5474\n",
      "Epoch: 086/100 | Batch 100/469 | Gen/Dis Loss: 1.3558/0.4627\n",
      "Epoch: 086/100 | Batch 200/469 | Gen/Dis Loss: 1.3680/0.4781\n",
      "Epoch: 086/100 | Batch 300/469 | Gen/Dis Loss: 1.2804/0.5160\n",
      "Epoch: 086/100 | Batch 400/469 | Gen/Dis Loss: 0.7773/0.5404\n",
      "Time elapsed: 14.29 min\n",
      "Epoch: 087/100 | Batch 000/469 | Gen/Dis Loss: 1.1318/0.5236\n",
      "Epoch: 087/100 | Batch 100/469 | Gen/Dis Loss: 1.0901/0.5380\n",
      "Epoch: 087/100 | Batch 200/469 | Gen/Dis Loss: 1.1667/0.5573\n",
      "Epoch: 087/100 | Batch 300/469 | Gen/Dis Loss: 1.1627/0.5312\n",
      "Epoch: 087/100 | Batch 400/469 | Gen/Dis Loss: 1.0313/0.4823\n",
      "Time elapsed: 14.46 min\n",
      "Epoch: 088/100 | Batch 000/469 | Gen/Dis Loss: 1.2402/0.4963\n",
      "Epoch: 088/100 | Batch 100/469 | Gen/Dis Loss: 1.0435/0.5739\n",
      "Epoch: 088/100 | Batch 200/469 | Gen/Dis Loss: 1.0051/0.5085\n",
      "Epoch: 088/100 | Batch 300/469 | Gen/Dis Loss: 1.3028/0.5108\n",
      "Epoch: 088/100 | Batch 400/469 | Gen/Dis Loss: 1.3638/0.4764\n",
      "Time elapsed: 14.63 min\n",
      "Epoch: 089/100 | Batch 000/469 | Gen/Dis Loss: 1.3713/0.5249\n",
      "Epoch: 089/100 | Batch 100/469 | Gen/Dis Loss: 0.8104/0.5163\n",
      "Epoch: 089/100 | Batch 200/469 | Gen/Dis Loss: 1.0738/0.5218\n",
      "Epoch: 089/100 | Batch 300/469 | Gen/Dis Loss: 1.0415/0.5177\n",
      "Epoch: 089/100 | Batch 400/469 | Gen/Dis Loss: 1.1530/0.5123\n",
      "Time elapsed: 14.80 min\n",
      "Epoch: 090/100 | Batch 000/469 | Gen/Dis Loss: 1.0764/0.5049\n",
      "Epoch: 090/100 | Batch 100/469 | Gen/Dis Loss: 1.6047/0.5134\n",
      "Epoch: 090/100 | Batch 200/469 | Gen/Dis Loss: 1.0021/0.5091\n",
      "Epoch: 090/100 | Batch 300/469 | Gen/Dis Loss: 1.4370/0.5039\n",
      "Epoch: 090/100 | Batch 400/469 | Gen/Dis Loss: 1.0528/0.4816\n",
      "Time elapsed: 14.96 min\n",
      "Epoch: 091/100 | Batch 000/469 | Gen/Dis Loss: 1.0049/0.5312\n",
      "Epoch: 091/100 | Batch 100/469 | Gen/Dis Loss: 1.1295/0.5329\n",
      "Epoch: 091/100 | Batch 200/469 | Gen/Dis Loss: 1.2192/0.4972\n",
      "Epoch: 091/100 | Batch 300/469 | Gen/Dis Loss: 0.9003/0.5170\n",
      "Epoch: 091/100 | Batch 400/469 | Gen/Dis Loss: 0.8378/0.5403\n",
      "Time elapsed: 15.13 min\n",
      "Epoch: 092/100 | Batch 000/469 | Gen/Dis Loss: 1.2640/0.5255\n",
      "Epoch: 092/100 | Batch 100/469 | Gen/Dis Loss: 1.3052/0.5846\n",
      "Epoch: 092/100 | Batch 200/469 | Gen/Dis Loss: 1.0858/0.5328\n",
      "Epoch: 092/100 | Batch 300/469 | Gen/Dis Loss: 1.0232/0.5136\n",
      "Epoch: 092/100 | Batch 400/469 | Gen/Dis Loss: 1.1835/0.5012\n",
      "Time elapsed: 15.30 min\n",
      "Epoch: 093/100 | Batch 000/469 | Gen/Dis Loss: 1.2059/0.5166\n",
      "Epoch: 093/100 | Batch 100/469 | Gen/Dis Loss: 1.2103/0.5029\n",
      "Epoch: 093/100 | Batch 200/469 | Gen/Dis Loss: 1.0087/0.4787\n",
      "Epoch: 093/100 | Batch 300/469 | Gen/Dis Loss: 0.8336/0.5502\n",
      "Epoch: 093/100 | Batch 400/469 | Gen/Dis Loss: 0.8723/0.5355\n",
      "Time elapsed: 15.46 min\n",
      "Epoch: 094/100 | Batch 000/469 | Gen/Dis Loss: 1.4476/0.5299\n",
      "Epoch: 094/100 | Batch 100/469 | Gen/Dis Loss: 0.9212/0.5202\n",
      "Epoch: 094/100 | Batch 200/469 | Gen/Dis Loss: 1.0392/0.5274\n",
      "Epoch: 094/100 | Batch 300/469 | Gen/Dis Loss: 0.8569/0.5185\n",
      "Epoch: 094/100 | Batch 400/469 | Gen/Dis Loss: 1.1016/0.5513\n",
      "Time elapsed: 15.63 min\n",
      "Epoch: 095/100 | Batch 000/469 | Gen/Dis Loss: 1.1735/0.5358\n",
      "Epoch: 095/100 | Batch 100/469 | Gen/Dis Loss: 1.2593/0.5149\n",
      "Epoch: 095/100 | Batch 200/469 | Gen/Dis Loss: 1.2433/0.5321\n",
      "Epoch: 095/100 | Batch 300/469 | Gen/Dis Loss: 1.1364/0.5693\n",
      "Epoch: 095/100 | Batch 400/469 | Gen/Dis Loss: 1.1025/0.5312\n",
      "Time elapsed: 15.80 min\n",
      "Epoch: 096/100 | Batch 000/469 | Gen/Dis Loss: 0.9824/0.5173\n",
      "Epoch: 096/100 | Batch 100/469 | Gen/Dis Loss: 0.8593/0.5692\n",
      "Epoch: 096/100 | Batch 200/469 | Gen/Dis Loss: 0.9763/0.5427\n",
      "Epoch: 096/100 | Batch 300/469 | Gen/Dis Loss: 0.8349/0.5884\n",
      "Epoch: 096/100 | Batch 400/469 | Gen/Dis Loss: 1.1850/0.5423\n",
      "Time elapsed: 15.97 min\n",
      "Epoch: 097/100 | Batch 000/469 | Gen/Dis Loss: 1.0163/0.5948\n",
      "Epoch: 097/100 | Batch 100/469 | Gen/Dis Loss: 1.1039/0.5266\n",
      "Epoch: 097/100 | Batch 200/469 | Gen/Dis Loss: 1.1505/0.5462\n",
      "Epoch: 097/100 | Batch 300/469 | Gen/Dis Loss: 0.7861/0.5833\n",
      "Epoch: 097/100 | Batch 400/469 | Gen/Dis Loss: 1.0289/0.5809\n",
      "Time elapsed: 16.14 min\n",
      "Epoch: 098/100 | Batch 000/469 | Gen/Dis Loss: 1.0072/0.5891\n",
      "Epoch: 098/100 | Batch 100/469 | Gen/Dis Loss: 1.0864/0.5699\n",
      "Epoch: 098/100 | Batch 200/469 | Gen/Dis Loss: 1.1489/0.5464\n",
      "Epoch: 098/100 | Batch 300/469 | Gen/Dis Loss: 1.2727/0.5798\n",
      "Epoch: 098/100 | Batch 400/469 | Gen/Dis Loss: 1.0470/0.5320\n",
      "Time elapsed: 16.31 min\n",
      "Epoch: 099/100 | Batch 000/469 | Gen/Dis Loss: 0.6077/0.6039\n",
      "Epoch: 099/100 | Batch 100/469 | Gen/Dis Loss: 0.9367/0.5878\n",
      "Epoch: 099/100 | Batch 200/469 | Gen/Dis Loss: 0.9805/0.5844\n",
      "Epoch: 099/100 | Batch 300/469 | Gen/Dis Loss: 0.8512/0.5655\n",
      "Epoch: 099/100 | Batch 400/469 | Gen/Dis Loss: 1.4205/0.6310\n",
      "Time elapsed: 16.47 min\n",
      "Epoch: 100/100 | Batch 000/469 | Gen/Dis Loss: 0.9023/0.6058\n",
      "Epoch: 100/100 | Batch 100/469 | Gen/Dis Loss: 1.0685/0.5535\n",
      "Epoch: 100/100 | Batch 200/469 | Gen/Dis Loss: 0.9407/0.5943\n",
      "Epoch: 100/100 | Batch 300/469 | Gen/Dis Loss: 0.8671/0.5903\n",
      "Epoch: 100/100 | Batch 400/469 | Gen/Dis Loss: 1.1570/0.5707\n",
      "Time elapsed: 16.63 min\n",
      "Total Training Time: 16.63 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()    \n",
    "\n",
    "discr_costs = []\n",
    "gener_costs = []\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "\n",
    "        \n",
    "        # Normalize images to [-1, 1] range\n",
    "        features = (features - 0.5)*2.\n",
    "        features = features.view(-1, IMG_SIZE).to(device) \n",
    "\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        valid = torch.ones(targets.size(0)).float().to(device)\n",
    "        fake = torch.zeros(targets.size(0)).float().to(device)\n",
    "        \n",
    "\n",
    "        ### FORWARD AND BACK PROP\n",
    "        \n",
    "        \n",
    "        # --------------------------\n",
    "        # Train Generator\n",
    "        # --------------------------\n",
    "        \n",
    "        # Make new images\n",
    "        z = torch.zeros((targets.size(0), LATENT_DIM)).uniform_(-1.0, 1.0).to(device)\n",
    "        generated_features = model.generator_forward(z)\n",
    "        \n",
    "        # Loss for fooling the discriminator\n",
    "        discr_pred = model.discriminator_forward(generated_features.view(targets.size(0), 1, 28, 28))\n",
    "        \n",
    "        gener_loss = F.binary_cross_entropy(discr_pred, valid)\n",
    "        \n",
    "        optim_gener.zero_grad()\n",
    "        gener_loss.backward()\n",
    "        optim_gener.step()\n",
    "        \n",
    "        # --------------------------\n",
    "        # Train Discriminator\n",
    "        # --------------------------        \n",
    "        \n",
    "        discr_pred_real = model.discriminator_forward(features.view(targets.size(0), 1, 28, 28))\n",
    "        real_loss = F.binary_cross_entropy(discr_pred_real, valid)\n",
    "        \n",
    "        discr_pred_fake = model.discriminator_forward(generated_features.view(targets.size(0), 1, 28, 28).detach())\n",
    "        fake_loss = F.binary_cross_entropy(discr_pred_fake, fake)\n",
    "        \n",
    "        discr_loss = 0.5*(real_loss + fake_loss)\n",
    "\n",
    "        optim_discr.zero_grad()\n",
    "        discr_loss.backward()\n",
    "        optim_discr.step()        \n",
    "        \n",
    "        discr_costs.append(discr_loss.item())\n",
    "        gener_costs.append(gener_loss.item())\n",
    "        \n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 100:\n",
    "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Gen/Dis Loss: %.4f/%.4f' \n",
    "                   %(epoch+1, num_epochs, batch_idx, \n",
    "                     len(train_loader), gener_loss, discr_loss))\n",
    "\n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in outputs:\\n    print(i.size())\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### For Debugging\n",
    "\n",
    "\"\"\"\n",
    "for i in outputs:\n",
    "    print(i.size())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(gener_costs)), gener_costs, label='generator loss')\n",
    "plt.plot(range(len(discr_costs)), discr_costs, label='discriminator loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x180 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################\n",
    "### VISUALIZATION\n",
    "##########################\n",
    "\n",
    "\n",
    "model.eval()\n",
    "# Make new images\n",
    "z = torch.zeros((5, LATENT_DIM)).uniform_(-1.0, 1.0).to(device)\n",
    "generated_features = model.generator_forward(z)\n",
    "imgs = generated_features.view(-1, 28, 28)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 2.5))\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    axes[i].imshow(imgs[i].to(torch.device('cpu')).detach(), cmap='binary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
