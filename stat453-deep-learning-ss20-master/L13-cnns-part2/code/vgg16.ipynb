{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEBilEjLj5wY"
   },
   "source": [
    "STAT 453: Deep Learning (Spring 2020)\n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)\n",
    "- Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2020/ \n",
    "- GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEu9MiOxj5wk"
   },
   "source": [
    "- Runs on CPU (not recommended here) or GPU (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rH4XmErYj5wm"
   },
   "source": [
    "# VGG16 Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.7.3\n",
      "IPython 7.9.0\n",
      "\n",
      "torch 1.4.0\n",
      "torchvision 0.5.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch,torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvgJ_0i7j5wt"
   },
   "source": [
    "## Settings and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', DEVICE)\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Image batch dimensions: torch.Size([256, 3, 32, 32])\n",
      "Image label dimensions: torch.Size([256])\n",
      "Image batch dimensions: torch.Size([256, 3, 32, 32])\n",
      "Image label dimensions: torch.Size([256])\n",
      "Image batch dimensions: torch.Size([256, 3, 32, 32])\n",
      "Image label dimensions: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### CIFAR-10 Dataset\n",
    "##########################\n",
    "\n",
    "\n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "\n",
    "\n",
    "train_indices = torch.arange(0, 49000)\n",
    "valid_indices = torch.arange(49000, 50000)\n",
    "\n",
    "\n",
    "train_and_valid = datasets.CIFAR10(root='data', \n",
    "                                   train=True, \n",
    "                                   transform=transforms.ToTensor(),\n",
    "                                   download=True)\n",
    "\n",
    "train_dataset = Subset(train_and_valid, train_indices)\n",
    "valid_dataset = Subset(train_and_valid, valid_indices)\n",
    "\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='data', \n",
    "                                train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "#####################################################\n",
    "### Data Loaders\n",
    "#####################################################\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=8,\n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=8,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=8,\n",
    "                         shuffle=False)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break\n",
    "\n",
    "for images, labels in test_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break\n",
    "    \n",
    "for images, labels in valid_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6hghKPxj5w0"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "class VGG16(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG16, self).__init__()\n",
    "        \n",
    "        # calculate same padding:\n",
    "        # (w - k + 2*p)/s + 1 = o\n",
    "        # => p = (s(o-1) - w + k)/2\n",
    "        \n",
    "        self.block_1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          # (1(32-1)- 32 + 3)/2 = 1\n",
    "                          padding=1), \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=128,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_3 = nn.Sequential(        \n",
    "                nn.Conv2d(in_channels=128,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),        \n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "          \n",
    "        self.block_4 = nn.Sequential(   \n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),        \n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),        \n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),            \n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_5 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),            \n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),            \n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),    \n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))             \n",
    "        )\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(True),\n",
    "            #nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            #nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "            \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.detach().zero_()\n",
    "                    \n",
    "        #self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.block_4(x)\n",
    "        x = self.block_5(x)\n",
    "        #x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.classifier(x)\n",
    "        #probas = F.softmax(logits, dim=1)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    \n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = VGG16(num_classes=NUM_CLASSES)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/050 | Batch 000/192 | Cost: 2.4079\n",
      "Epoch: 001/050 | Batch 120/192 | Cost: 1.4262\n",
      "Epoch: 001/050 Train Acc.: 47.37% | Validation Acc.: 49.80%\n",
      "Time elapsed: 0.37 min\n",
      "Epoch: 002/050 | Batch 000/192 | Cost: 1.5094\n",
      "Epoch: 002/050 | Batch 120/192 | Cost: 1.2342\n",
      "Epoch: 002/050 Train Acc.: 62.17% | Validation Acc.: 58.40%\n",
      "Time elapsed: 0.74 min\n",
      "Epoch: 003/050 | Batch 000/192 | Cost: 1.0476\n",
      "Epoch: 003/050 | Batch 120/192 | Cost: 1.0057\n",
      "Epoch: 003/050 Train Acc.: 64.67% | Validation Acc.: 61.90%\n",
      "Time elapsed: 1.13 min\n",
      "Epoch: 004/050 | Batch 000/192 | Cost: 0.9690\n",
      "Epoch: 004/050 | Batch 120/192 | Cost: 0.8387\n",
      "Epoch: 004/050 Train Acc.: 66.03% | Validation Acc.: 59.40%\n",
      "Time elapsed: 1.53 min\n",
      "Epoch: 005/050 | Batch 000/192 | Cost: 0.9286\n",
      "Epoch: 005/050 | Batch 120/192 | Cost: 0.6450\n",
      "Epoch: 005/050 Train Acc.: 80.82% | Validation Acc.: 66.90%\n",
      "Time elapsed: 1.92 min\n",
      "Epoch: 006/050 | Batch 000/192 | Cost: 0.5529\n",
      "Epoch: 006/050 | Batch 120/192 | Cost: 0.5474\n",
      "Epoch: 006/050 Train Acc.: 84.51% | Validation Acc.: 69.70%\n",
      "Time elapsed: 2.31 min\n",
      "Epoch: 007/050 | Batch 000/192 | Cost: 0.4570\n",
      "Epoch: 007/050 | Batch 120/192 | Cost: 0.4224\n",
      "Epoch: 007/050 Train Acc.: 85.61% | Validation Acc.: 67.70%\n",
      "Time elapsed: 2.70 min\n",
      "Epoch: 008/050 | Batch 000/192 | Cost: 0.4075\n",
      "Epoch: 008/050 | Batch 120/192 | Cost: 0.4199\n",
      "Epoch: 008/050 Train Acc.: 88.46% | Validation Acc.: 68.40%\n",
      "Time elapsed: 3.08 min\n",
      "Epoch: 009/050 | Batch 000/192 | Cost: 0.2506\n",
      "Epoch: 009/050 | Batch 120/192 | Cost: 0.3242\n",
      "Epoch: 009/050 Train Acc.: 94.43% | Validation Acc.: 69.90%\n",
      "Time elapsed: 3.47 min\n",
      "Epoch: 010/050 | Batch 000/192 | Cost: 0.1464\n",
      "Epoch: 010/050 | Batch 120/192 | Cost: 0.1666\n",
      "Epoch: 010/050 Train Acc.: 94.75% | Validation Acc.: 69.30%\n",
      "Time elapsed: 3.86 min\n",
      "Epoch: 011/050 | Batch 000/192 | Cost: 0.1825\n",
      "Epoch: 011/050 | Batch 120/192 | Cost: 0.1115\n",
      "Epoch: 011/050 Train Acc.: 93.83% | Validation Acc.: 67.80%\n",
      "Time elapsed: 4.25 min\n",
      "Epoch: 012/050 | Batch 000/192 | Cost: 0.2027\n",
      "Epoch: 012/050 | Batch 120/192 | Cost: 0.1729\n",
      "Epoch: 012/050 Train Acc.: 93.88% | Validation Acc.: 67.80%\n",
      "Time elapsed: 4.64 min\n",
      "Epoch: 013/050 | Batch 000/192 | Cost: 0.2036\n",
      "Epoch: 013/050 | Batch 120/192 | Cost: 0.1511\n",
      "Epoch: 013/050 Train Acc.: 97.22% | Validation Acc.: 70.70%\n",
      "Time elapsed: 5.03 min\n",
      "Epoch: 014/050 | Batch 000/192 | Cost: 0.0773\n",
      "Epoch: 014/050 | Batch 120/192 | Cost: 0.1846\n",
      "Epoch: 014/050 Train Acc.: 97.69% | Validation Acc.: 68.90%\n",
      "Time elapsed: 5.43 min\n",
      "Epoch: 015/050 | Batch 000/192 | Cost: 0.0653\n",
      "Epoch: 015/050 | Batch 120/192 | Cost: 0.1209\n",
      "Epoch: 015/050 Train Acc.: 97.29% | Validation Acc.: 70.10%\n",
      "Time elapsed: 5.82 min\n",
      "Epoch: 016/050 | Batch 000/192 | Cost: 0.0754\n",
      "Epoch: 016/050 | Batch 120/192 | Cost: 0.0924\n",
      "Epoch: 016/050 Train Acc.: 98.44% | Validation Acc.: 69.30%\n",
      "Time elapsed: 6.22 min\n",
      "Epoch: 017/050 | Batch 000/192 | Cost: 0.0414\n",
      "Epoch: 017/050 | Batch 120/192 | Cost: 0.1235\n",
      "Epoch: 017/050 Train Acc.: 98.18% | Validation Acc.: 69.70%\n",
      "Time elapsed: 6.61 min\n",
      "Epoch: 018/050 | Batch 000/192 | Cost: 0.0717\n",
      "Epoch: 018/050 | Batch 120/192 | Cost: 0.0949\n",
      "Epoch: 018/050 Train Acc.: 98.39% | Validation Acc.: 70.70%\n",
      "Time elapsed: 7.01 min\n",
      "Epoch: 019/050 | Batch 000/192 | Cost: 0.0379\n",
      "Epoch: 019/050 | Batch 120/192 | Cost: 0.0962\n",
      "Epoch: 019/050 Train Acc.: 98.47% | Validation Acc.: 70.10%\n",
      "Time elapsed: 7.40 min\n",
      "Epoch: 020/050 | Batch 000/192 | Cost: 0.0530\n",
      "Epoch: 020/050 | Batch 120/192 | Cost: 0.1007\n",
      "Epoch: 020/050 Train Acc.: 98.21% | Validation Acc.: 71.30%\n",
      "Time elapsed: 7.80 min\n",
      "Epoch: 021/050 | Batch 000/192 | Cost: 0.0331\n",
      "Epoch: 021/050 | Batch 120/192 | Cost: 0.0562\n",
      "Epoch: 021/050 Train Acc.: 98.89% | Validation Acc.: 70.40%\n",
      "Time elapsed: 8.18 min\n",
      "Epoch: 022/050 | Batch 000/192 | Cost: 0.0572\n",
      "Epoch: 022/050 | Batch 120/192 | Cost: 0.1118\n",
      "Epoch: 022/050 Train Acc.: 99.03% | Validation Acc.: 71.80%\n",
      "Time elapsed: 8.58 min\n",
      "Epoch: 023/050 | Batch 000/192 | Cost: 0.0295\n",
      "Epoch: 023/050 | Batch 120/192 | Cost: 0.1505\n",
      "Epoch: 023/050 Train Acc.: 99.06% | Validation Acc.: 72.30%\n",
      "Time elapsed: 8.97 min\n",
      "Epoch: 024/050 | Batch 000/192 | Cost: 0.0115\n",
      "Epoch: 024/050 | Batch 120/192 | Cost: 0.0642\n",
      "Epoch: 024/050 Train Acc.: 98.23% | Validation Acc.: 70.70%\n",
      "Time elapsed: 9.36 min\n",
      "Epoch: 025/050 | Batch 000/192 | Cost: 0.0325\n",
      "Epoch: 025/050 | Batch 120/192 | Cost: 0.0177\n",
      "Epoch: 025/050 Train Acc.: 98.88% | Validation Acc.: 69.70%\n",
      "Time elapsed: 9.76 min\n",
      "Epoch: 026/050 | Batch 000/192 | Cost: 0.0254\n",
      "Epoch: 026/050 | Batch 120/192 | Cost: 0.0395\n",
      "Epoch: 026/050 Train Acc.: 98.60% | Validation Acc.: 71.90%\n",
      "Time elapsed: 10.15 min\n",
      "Epoch: 027/050 | Batch 000/192 | Cost: 0.0540\n",
      "Epoch: 027/050 | Batch 120/192 | Cost: 0.0206\n",
      "Epoch: 027/050 Train Acc.: 99.02% | Validation Acc.: 71.50%\n",
      "Time elapsed: 10.55 min\n",
      "Epoch: 028/050 | Batch 000/192 | Cost: 0.0408\n",
      "Epoch: 028/050 | Batch 120/192 | Cost: 0.0410\n",
      "Epoch: 028/050 Train Acc.: 98.19% | Validation Acc.: 70.70%\n",
      "Time elapsed: 10.94 min\n",
      "Epoch: 029/050 | Batch 000/192 | Cost: 0.0517\n",
      "Epoch: 029/050 | Batch 120/192 | Cost: 0.0649\n",
      "Epoch: 029/050 Train Acc.: 99.11% | Validation Acc.: 71.70%\n",
      "Time elapsed: 11.34 min\n",
      "Epoch: 030/050 | Batch 000/192 | Cost: 0.0298\n",
      "Epoch: 030/050 | Batch 120/192 | Cost: 0.0391\n",
      "Epoch: 030/050 Train Acc.: 98.96% | Validation Acc.: 71.50%\n",
      "Time elapsed: 11.72 min\n",
      "Epoch: 031/050 | Batch 000/192 | Cost: 0.0485\n",
      "Epoch: 031/050 | Batch 120/192 | Cost: 0.0520\n",
      "Epoch: 031/050 Train Acc.: 98.15% | Validation Acc.: 69.80%\n",
      "Time elapsed: 12.12 min\n",
      "Epoch: 032/050 | Batch 000/192 | Cost: 0.0671\n",
      "Epoch: 032/050 | Batch 120/192 | Cost: 0.0180\n",
      "Epoch: 032/050 Train Acc.: 97.30% | Validation Acc.: 70.20%\n",
      "Time elapsed: 12.52 min\n",
      "Epoch: 033/050 | Batch 000/192 | Cost: 0.0612\n",
      "Epoch: 033/050 | Batch 120/192 | Cost: 0.0085\n",
      "Epoch: 033/050 Train Acc.: 98.60% | Validation Acc.: 71.00%\n",
      "Time elapsed: 12.91 min\n",
      "Epoch: 034/050 | Batch 000/192 | Cost: 0.0454\n",
      "Epoch: 034/050 | Batch 120/192 | Cost: 0.0205\n",
      "Epoch: 034/050 Train Acc.: 98.84% | Validation Acc.: 71.50%\n",
      "Time elapsed: 13.31 min\n",
      "Epoch: 035/050 | Batch 000/192 | Cost: 0.0263\n",
      "Epoch: 035/050 | Batch 120/192 | Cost: 0.0241\n",
      "Epoch: 035/050 Train Acc.: 98.97% | Validation Acc.: 72.20%\n",
      "Time elapsed: 13.70 min\n",
      "Epoch: 036/050 | Batch 000/192 | Cost: 0.0359\n",
      "Epoch: 036/050 | Batch 120/192 | Cost: 0.0851\n",
      "Epoch: 036/050 Train Acc.: 98.59% | Validation Acc.: 71.10%\n",
      "Time elapsed: 14.10 min\n",
      "Epoch: 037/050 | Batch 000/192 | Cost: 0.0229\n",
      "Epoch: 037/050 | Batch 120/192 | Cost: 0.0520\n",
      "Epoch: 037/050 Train Acc.: 97.87% | Validation Acc.: 71.50%\n",
      "Time elapsed: 14.50 min\n",
      "Epoch: 038/050 | Batch 000/192 | Cost: 0.1142\n",
      "Epoch: 038/050 | Batch 120/192 | Cost: 0.0384\n",
      "Epoch: 038/050 Train Acc.: 97.56% | Validation Acc.: 70.60%\n",
      "Time elapsed: 14.90 min\n",
      "Epoch: 039/050 | Batch 000/192 | Cost: 0.0575\n",
      "Epoch: 039/050 | Batch 120/192 | Cost: 0.0284\n",
      "Epoch: 039/050 Train Acc.: 98.79% | Validation Acc.: 70.70%\n",
      "Time elapsed: 15.29 min\n",
      "Epoch: 040/050 | Batch 000/192 | Cost: 0.0714\n",
      "Epoch: 040/050 | Batch 120/192 | Cost: 0.0366\n",
      "Epoch: 040/050 Train Acc.: 98.51% | Validation Acc.: 71.00%\n",
      "Time elapsed: 15.69 min\n",
      "Epoch: 041/050 | Batch 000/192 | Cost: 0.0737\n",
      "Epoch: 041/050 | Batch 120/192 | Cost: 0.0326\n",
      "Epoch: 041/050 Train Acc.: 98.81% | Validation Acc.: 71.90%\n",
      "Time elapsed: 16.08 min\n",
      "Epoch: 042/050 | Batch 000/192 | Cost: 0.0421\n",
      "Epoch: 042/050 | Batch 120/192 | Cost: 0.0670\n",
      "Epoch: 042/050 Train Acc.: 98.86% | Validation Acc.: 72.70%\n",
      "Time elapsed: 16.48 min\n",
      "Epoch: 043/050 | Batch 000/192 | Cost: 0.0147\n",
      "Epoch: 043/050 | Batch 120/192 | Cost: 0.0133\n",
      "Epoch: 043/050 Train Acc.: 99.01% | Validation Acc.: 71.40%\n",
      "Time elapsed: 16.88 min\n",
      "Epoch: 044/050 | Batch 000/192 | Cost: 0.0421\n",
      "Epoch: 044/050 | Batch 120/192 | Cost: 0.0682\n",
      "Epoch: 044/050 Train Acc.: 99.22% | Validation Acc.: 72.80%\n",
      "Time elapsed: 17.27 min\n",
      "Epoch: 045/050 | Batch 000/192 | Cost: 0.0106\n",
      "Epoch: 045/050 | Batch 120/192 | Cost: 0.0054\n",
      "Epoch: 045/050 Train Acc.: 99.37% | Validation Acc.: 72.50%\n",
      "Time elapsed: 17.67 min\n",
      "Epoch: 046/050 | Batch 000/192 | Cost: 0.0148\n",
      "Epoch: 046/050 | Batch 120/192 | Cost: 0.0766\n",
      "Epoch: 046/050 Train Acc.: 99.18% | Validation Acc.: 72.80%\n",
      "Time elapsed: 18.07 min\n",
      "Epoch: 047/050 | Batch 000/192 | Cost: 0.0335\n",
      "Epoch: 047/050 | Batch 120/192 | Cost: 0.0328\n",
      "Epoch: 047/050 Train Acc.: 98.73% | Validation Acc.: 70.20%\n",
      "Time elapsed: 18.46 min\n",
      "Epoch: 048/050 | Batch 000/192 | Cost: 0.0229\n",
      "Epoch: 048/050 | Batch 120/192 | Cost: 0.0258\n",
      "Epoch: 048/050 Train Acc.: 99.03% | Validation Acc.: 72.30%\n",
      "Time elapsed: 18.86 min\n",
      "Epoch: 049/050 | Batch 000/192 | Cost: 0.0587\n",
      "Epoch: 049/050 | Batch 120/192 | Cost: 0.0790\n",
      "Epoch: 049/050 Train Acc.: 98.58% | Validation Acc.: 71.40%\n",
      "Time elapsed: 19.24 min\n",
      "Epoch: 050/050 | Batch 000/192 | Cost: 0.0152\n",
      "Epoch: 050/050 | Batch 120/192 | Cost: 0.0346\n",
      "Epoch: 050/050 Train Acc.: 98.80% | Validation Acc.: 72.40%\n",
      "Time elapsed: 19.63 min\n",
      "Total Training Time: 19.63 min\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits = model(features)\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# use random seed for reproducibility (here batch shuffling)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "    \n",
    "        ### PREPARE MINIBATCH\n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 120:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "                   f' Cost: {cost:.4f}')\n",
    "\n",
    "    # no need to build the computation graph for backprop when computing accuracy\n",
    "    with torch.set_grad_enabled(False):\n",
    "        train_acc = compute_accuracy(model, train_loader, device=DEVICE)\n",
    "        valid_acc = compute_accuracy(model, valid_loader, device=DEVICE)\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "              f' | Validation Acc.: {valid_acc:.2f}%')\n",
    "        \n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paaeEQHQj5xC"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6514,
     "status": "ok",
     "timestamp": 1524976895054,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "gzQMWKq5j5xE",
    "outputId": "de7dc005-5eeb-4177-9f9f-d9b5d1358db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 70.27%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
